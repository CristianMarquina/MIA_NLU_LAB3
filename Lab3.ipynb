{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2850f8b6-4428-4c96-a969-725832d54cd6",
   "metadata": {},
   "source": [
    "## Stage 2: Data Preparation Pipeline & Feature Extraction\n",
    "\n",
    "Milestone: Implementation of the oracle, feature extraction, and obtaining training samples for a Keras model.\n",
    "\n",
    "In this section, we execute the complete data processing pipeline to transform the raw CoNLL-U training data into numerical vectors that can be fed into the Neural Network. This process involves four main steps:\n",
    "\n",
    "\n",
    "Data Loading & Filtering: We load the training dataset (en_partut-ud-train.conllu) and filter out non-projective trees, as the Arc-Eager algorithm is restricted to projective dependency structures.\n",
    "\n",
    "Oracle Execution (Obtaining Samples): We run the Oracle on every valid sentence. The Oracle simulates the parsing process using the \"gold standard\" tree to generate the correct sequence of States (Input) and Transitions (Output/Target).\n",
    "\n",
    "\n",
    "Feature Extraction: We convert the complex State objects into fixed-length lists of features using the state_to_feats function. This extracts the specific words and UPOS tags from the top of the Stack and the Buffer.\n",
    "\n",
    "\n",
    "Numerical Conversion (Vectorization): Neural networks require numerical input. We build vocabularies (dictionaries mapping strings to unique Integer IDs) for words, tags, actions, and dependency labels. Finally, we convert all text features into Numpy arrays (X_train, y_act, y_dep) ready for Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119375a6-1679-4692-a15b-b51a760802b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Data Loading ---\n",
      " Loaded 1748 valid projective sentences for training.\n",
      "\n",
      "--- STEP 2: Generating Samples with the Oracle ---\n",
      "Total samples (game states) generated: 81182\n",
      "Example of Raw Sample (Index 0):\n",
      "   State: Stack (size=1): (0, ROOT, ROOT_UPOS)\n",
      "Buffer (size=13): (1, Distribution, NOUN) | (2, of, ADP) | (3, this, DET) | (4, license, NOUN) | (5, does, AUX) | (6, not, PART) | (7, create, VERB) | (8, an, DET) | (9, attorney, NOUN) | (10, -, PUNCT) | (11, client, NOUN) | (12, relationship, NOUN) | (13, ., PUNCT)\n",
      "Arcs (size=0): set()\n",
      "\n",
      "   Correct Action: SHIFT\n",
      "\n",
      "--- STEP 3: Feature Extraction (Translation to Text) ---\n",
      " Example of Input (X_raw[0]): ['<PAD>', 'ROOT', 'Distribution', 'of', '<PAD>', 'ROOT_UPOS', 'NOUN', 'ADP']\n",
      "   (This is what the network 'sees': words and tags)\n",
      "Example of Output (Y_raw[0]): ('SHIFT', None)\n",
      "   (This is what the network must predict: Action and Label)\n",
      "\n",
      "--- STEP 4: Numerical Conversion (For Keras) ---\n",
      "Vocabulary Sizes:\n",
      "   Unique words: 6872\n",
      "   Unique UPOS tags: 20\n",
      "   Possible actions: 4 {'SHIFT': 0, 'LEFT-ARC': 1, 'RIGHT-ARC': 2, 'REDUCE': 3}\n",
      "   Dependency relations: 44\n",
      "\n",
      "DATA\n",
      "Final numerical example (X_train[0]): [0 2 3 4 0 2 3 4]\n",
      "   (Notice how words are now IDs)\n",
      "Target Action (y_act[0]): 0 -> Corresponds to 'SHIFT'\n",
      "Target Action (y_act[0]): 0 -> Corresponds to 'SHIFT'\n",
      "Data saved to 'training_data.npz' and 'vocabs.pkl'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from conllu_reader import ConlluReader\n",
    "from algorithm import ArcEager\n",
    "import pickle\n",
    "\n",
    "# --- 1. LOAD DATA (Use the TRAIN file, not test) ---\n",
    "print(\"--- STEP 1: Data Loading ---\")\n",
    "reader = ConlluReader()\n",
    "# Ensure the filename matches your specific training file path\n",
    "train_sentences = reader.read_conllu_file(\"en_partut-ud-train_clean.conllu\") \n",
    "\n",
    "# Filter out non-projective trees as Arc-Eager cannot handle them [cite: 1100]\n",
    "train_sentences = reader.remove_non_projective_trees(train_sentences)\n",
    "print(f\" Loaded {len(train_sentences)} valid projective sentences for training.\\n\")\n",
    "\n",
    "# --- 2. OBTAIN RAW SAMPLES (Oracle Execution) ---\n",
    "print(\"--- STEP 2: Generating Samples with the Oracle ---\")\n",
    "arc_eager = ArcEager()\n",
    "raw_samples = []\n",
    "\n",
    "for sent in train_sentences:\n",
    "    try:\n",
    "        # The oracle returns a list of Sample objects (State + Transition) for this sentence\n",
    "        samples = arc_eager.oracle(sent)\n",
    "        raw_samples.extend(samples)\n",
    "    except AssertionError:\n",
    "        # If the oracle fails to reconstruct the exact gold tree, skip the sentence\n",
    "        continue\n",
    "\n",
    "print(f\"Total samples (game states) generated: {len(raw_samples)}\")\n",
    "\n",
    "# VISUALIZATION: Let's see what a raw sample looks like\n",
    "if raw_samples:\n",
    "    print(f\"Example of Raw Sample (Index 0):\")\n",
    "    print(f\"   State: {raw_samples[0].state}\")\n",
    "    print(f\"   Correct Action: {raw_samples[0].transition}\\n\")\n",
    "\n",
    "# --- 3. FEATURE EXTRACTION (From State to List of Strings) ---\n",
    "# We need to extract features from the stack and buffer [cite: 934, 1080]\n",
    "print(\"--- STEP 3: Feature Extraction (Translation to Text) ---\")\n",
    "X_raw = [] # Stores lists of words/tags (Input features)\n",
    "Y_raw = [] # Stores actions and dependencies (Outputs)\n",
    "\n",
    "for sample in raw_samples:\n",
    "    # Extract features (words and UPOS tags) using the implemented function\n",
    "    # nbuffer_feats=2 and nstack_feats=2 is the suggested configuration [cite: 1091]\n",
    "    features = sample.state_to_feats(nbuffer_feats=2, nstack_feats=2)\n",
    "    X_raw.append(features)\n",
    "    \n",
    "    # Save the action (transition) and the dependency label\n",
    "    action_name = sample.transition.action\n",
    "    dep_label = sample.transition.dependency\n",
    "    Y_raw.append((action_name, dep_label))\n",
    "\n",
    "# VISUALIZATION: What do the lists contain now?\n",
    "print(f\" Example of Input (X_raw[0]): {X_raw[0]}\")\n",
    "print(f\"   (This is what the network 'sees': words and tags)\")\n",
    "print(f\"Example of Output (Y_raw[0]): {Y_raw[0]}\")\n",
    "print(f\"   (This is what the network must predict: Action and Label)\\n\")\n",
    "\n",
    "# --- 4. PREPARATION FOR KERAS (Vocabularies and Numerical Conversion) ---\n",
    "# Neural networks require numerical input [cite: 733]\n",
    "print(\"--- STEP 4: Numerical Conversion (For Keras) ---\")\n",
    "\n",
    "# 4.1 Create Dictionaries (Text -> Number Maps)\n",
    "words_vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "upos_vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "actions_vocab = {}  # E.g., 'SHIFT': 0, 'LEFT-ARC': 1...\n",
    "deprels_vocab = {None: 0} # E.g., 'nsubj': 1, 'det': 2...\n",
    "\n",
    "# Fill vocabularies by iterating through all collected data\n",
    "for features in X_raw:\n",
    "    # Assuming features structure: [W_s2, W_s1, W_b1, W_b2, P_s2, P_s1, P_b1, P_b2]\n",
    "    # The first half are words, the second half are UPOS tags\n",
    "    num_words = len(features) // 2 \n",
    "    \n",
    "    words = features[:num_words]\n",
    "    upos = features[num_words:]\n",
    "    \n",
    "    for w in words:\n",
    "        if w not in words_vocab:\n",
    "            words_vocab[w] = len(words_vocab)\n",
    "    for u in upos:\n",
    "        if u not in upos_vocab:\n",
    "            upos_vocab[u] = len(upos_vocab)\n",
    "\n",
    "for act, dep in Y_raw:\n",
    "    if act not in actions_vocab:\n",
    "        actions_vocab[act] = len(actions_vocab)\n",
    "    if dep not in deprels_vocab:\n",
    "        deprels_vocab[dep] = len(deprels_vocab)\n",
    "\n",
    "print(f\"Vocabulary Sizes:\")\n",
    "print(f\"   Unique words: {len(words_vocab)}\")\n",
    "print(f\"   Unique UPOS tags: {len(upos_vocab)}\")\n",
    "print(f\"   Possible actions: {len(actions_vocab)} {actions_vocab}\")\n",
    "print(f\"   Dependency relations: {len(deprels_vocab)}\\n\")\n",
    "\n",
    "# 4.2 Convert everything to Numbers (Matrices for Keras)\n",
    "# X_train will have shape (Num_Samples, Num_Features)\n",
    "X_train_numerical = []\n",
    "Y_train_actions = []\n",
    "Y_train_deprels = []\n",
    "\n",
    "for i in range(len(X_raw)):\n",
    "    # Convert INPUT (Features)\n",
    "    features = X_raw[i]\n",
    "    num_vec = []\n",
    "    \n",
    "    # Convert words to IDs\n",
    "    num_words = len(features) // 2\n",
    "    for w in features[:num_words]:\n",
    "        num_vec.append(words_vocab.get(w, words_vocab['<UNK>']))\n",
    "    # Convert UPOS tags to IDs\n",
    "    for u in features[num_words:]:\n",
    "        num_vec.append(upos_vocab.get(u, upos_vocab['<UNK>']))\n",
    "    \n",
    "    X_train_numerical.append(num_vec)\n",
    "    \n",
    "    # Convert OUTPUT (Targets)\n",
    "    act, dep = Y_raw[i]\n",
    "    Y_train_actions.append(actions_vocab[act])\n",
    "    # Use 0 if the dependency is None (e.g., for SHIFT or REDUCE)\n",
    "    Y_train_deprels.append(deprels_vocab.get(dep, 0)) \n",
    "\n",
    "# Convert to Numpy arrays (The actual input format Keras expects)\n",
    "X_train = np.array(X_train_numerical)\n",
    "y_act = np.array(Y_train_actions)\n",
    "y_dep = np.array(Y_train_deprels)\n",
    "\n",
    "print(\"DATA\")\n",
    "print(f\"Final numerical example (X_train[0]): {X_train[0]}\")\n",
    "print(f\"   (Notice how words are now IDs)\")\n",
    "# Find the action name corresponding to the ID for display purposes\n",
    "act_name = list(actions_vocab.keys())[list(actions_vocab.values()).index(y_act[0])]\n",
    "print(f\"Target Action (y_act[0]): {y_act[0]} -> Corresponds to '{act_name}'\")\n",
    "\n",
    "print(f\"Target Action (y_act[0]): {y_act[0]} -> Corresponds to '{act_name}'\")\n",
    "np.savez(\"training_data.npz\", X=X_train, y_act=y_act, y_dep=y_dep)\n",
    "with open(\"vocabs.pkl\", \"wb\") as f:\n",
    "    pickle.dump((words_vocab, upos_vocab, actions_vocab, deprels_vocab), f)\n",
    "print(\"Data saved to 'training_data.npz' and 'vocabs.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2865f5-40b2-46d9-bc29-f8b9e505bb47",
   "metadata": {},
   "source": [
    "## Verificaion del oracle que esta haciendo bien su trabajo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6d5a0e-388c-4f55-8cc1-a5cbf3c55d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VERIFICACIÓN: Oracle vs Gold Standard + Input Red Neuronal ---\n",
      "Oración: ['ROOT', 'Distribution', 'of', 'this', 'license', 'does', 'not', 'create', 'an', 'attorney', '-', 'client', 'relationship', '.']\n",
      "Paso | Pila (Stack)              | Búfer (Buffer)            | Acción Real     | Input para Red Neuronal (Features)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "0    | ['ROOT']                  | ['Distribution', 'of']... | SHIFT           | ['<PAD>', 'ROOT', 'Distribution', 'of', '<PAD>', 'ROOT_UPOS', 'NOUN', 'ADP']\n",
      "1    | ['ROOT', 'Distribution']  | ['of', 'this']...         | SHIFT           | ['ROOT', 'Distribution', 'of', 'this', 'ROOT_UPOS', 'NOUN', 'ADP', 'DET']\n",
      "2    | T', 'Distribution', 'of'] | ['this', 'license']...    | SHIFT           | ['Distribution', 'of', 'this', 'license', 'NOUN', 'ADP', 'DET', 'NOUN']\n",
      "3    | tribution', 'of', 'this'] | ['license', 'does']...    | LEFT-ARC-det    | ['of', 'this', 'license', 'does', 'ADP', 'DET', 'NOUN', 'AUX']\n",
      "4    | T', 'Distribution', 'of'] | ['license', 'does']...    | LEFT-ARC-case   | ['Distribution', 'of', 'license', 'does', 'NOUN', 'ADP', 'NOUN', 'AUX']\n",
      "5    | ['ROOT', 'Distribution']  | ['license', 'does']...    | RIGHT-ARC-nmod  | ['ROOT', 'Distribution', 'license', 'does', 'ROOT_UPOS', 'NOUN', 'NOUN', 'AUX']\n",
      "6    | Distribution', 'license'] | ['does', 'not']...        | REDUCE          | ['Distribution', 'license', 'does', 'not', 'NOUN', 'NOUN', 'AUX', 'PART']\n",
      "7    | ['ROOT', 'Distribution']  | ['does', 'not']...        | SHIFT           | ['ROOT', 'Distribution', 'does', 'not', 'ROOT_UPOS', 'NOUN', 'AUX', 'PART']\n",
      "8    | , 'Distribution', 'does'] | ['not', 'create']...      | SHIFT           | ['Distribution', 'does', 'not', 'create', 'NOUN', 'AUX', 'PART', 'VERB']\n",
      "9    | ribution', 'does', 'not'] | ['create', 'an']...       | LEFT-ARC-advmod | ['does', 'not', 'create', 'an', 'AUX', 'PART', 'VERB', 'DET']\n",
      "10   | , 'Distribution', 'does'] | ['create', 'an']...       | LEFT-ARC-aux    | ['Distribution', 'does', 'create', 'an', 'NOUN', 'AUX', 'VERB', 'DET']\n",
      "11   | ['ROOT', 'Distribution']  | ['create', 'an']...       | LEFT-ARC-nsubj  | ['ROOT', 'Distribution', 'create', 'an', 'ROOT_UPOS', 'NOUN', 'VERB', 'DET']\n",
      "12   | ['ROOT']                  | ['create', 'an']...       | RIGHT-ARC-root  | ['<PAD>', 'ROOT', 'create', 'an', '<PAD>', 'ROOT_UPOS', 'VERB', 'DET']\n",
      "13   | ['ROOT', 'create']        | ['an', 'attorney']...     | SHIFT           | ['ROOT', 'create', 'an', 'attorney', 'ROOT_UPOS', 'VERB', 'DET', 'NOUN']\n",
      "14   | ['ROOT', 'create', 'an']  | ['attorney', '-']...      | SHIFT           | ['create', 'an', 'attorney', '-', 'VERB', 'DET', 'NOUN', 'PUNCT']\n",
      "15   | reate', 'an', 'attorney'] | ['-', 'client']...        | RIGHT-ARC-punct | ['an', 'attorney', '-', 'client', 'DET', 'NOUN', 'PUNCT', 'NOUN']\n",
      "16   | ', 'an', 'attorney', '-'] | ['client', 'relationship']... | REDUCE          | ['attorney', '-', 'client', 'relationship', 'NOUN', 'PUNCT', 'NOUN', 'NOUN']\n",
      "17   | reate', 'an', 'attorney'] | ['client', 'relationship']... | RIGHT-ARC-compound | ['an', 'attorney', 'client', 'relationship', 'DET', 'NOUN', 'NOUN', 'NOUN']\n",
      "18   | n', 'attorney', 'client'] | ['relationship', '.']...  | REDUCE          | ['attorney', 'client', 'relationship', '.', 'NOUN', 'NOUN', 'NOUN', 'PUNCT']\n",
      "19   | reate', 'an', 'attorney'] | ['relationship', '.']...  | LEFT-ARC-nmod   | ['an', 'attorney', 'relationship', '.', 'DET', 'NOUN', 'NOUN', 'PUNCT']\n",
      "20   | ['ROOT', 'create', 'an']  | ['relationship', '.']...  | LEFT-ARC-det    | ['create', 'an', 'relationship', '.', 'VERB', 'DET', 'NOUN', 'PUNCT']\n",
      "21   | ['ROOT', 'create']        | ['relationship', '.']...  | RIGHT-ARC-obj   | ['ROOT', 'create', 'relationship', '.', 'ROOT_UPOS', 'VERB', 'NOUN', 'PUNCT']\n",
      "22   | 'create', 'relationship'] | ['.']...                  | REDUCE          | ['create', 'relationship', '.', '<PAD>', 'VERB', 'NOUN', 'PUNCT', '<PAD>']\n",
      "23   | ['ROOT', 'create']        | ['.']...                  | RIGHT-ARC-punct | ['ROOT', 'create', '.', '<PAD>', 'ROOT_UPOS', 'VERB', 'PUNCT', '<PAD>']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Comparación de Arcos (Dependencias):\n",
      "Total arcos Gold (Reales): 13\n",
      "Total arcos Generados: 13\n",
      "\n",
      "✅ ¡ÉXITO! El oráculo reconstruyó el árbol perfectamente.\n",
      "Los inputs mostrados arriba son correctos para entrenar la red.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- VERIFICACIÓN: Oracle vs Gold Standard + Input Red Neuronal ---\")\n",
    "\n",
    "# 1. Seleccionamos una oración de ejemplo\n",
    "example_sent = train_sentences[0]\n",
    "print(f\"Oración: {[t.form for t in example_sent]}\")\n",
    "\n",
    "# 2. Obtenemos las transiciones del oráculo\n",
    "try:\n",
    "    oracle_samples = arc_eager.oracle(example_sent)\n",
    "except AssertionError as e:\n",
    "    print(f\"El oráculo falló en esta oración: {e}\")\n",
    "else:\n",
    "    # 3. Simulamos el parseo paso a paso\n",
    "    # CORRECCIÓN: Usamos el método correcto 'create_initial_state'\n",
    "    config = arc_eager.create_initial_state(example_sent)\n",
    "    \n",
    "    print(f\"{'Paso':<4} | {'Pila (Stack)':<25} | {'Búfer (Buffer)':<25} | {'Acción Real':<15} | {'Input para Red Neuronal (Features)'}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    for i, sample in enumerate(oracle_samples):\n",
    "        # Preparamos visualización del estado\n",
    "        stack_str = str([t.form for t in config.S])\n",
    "        buffer_str = str([t.form for t in config.B[:2]]) + \"...\" # Solo los primeros 2 del buffer\n",
    "        \n",
    "        # Acción tomada\n",
    "        action_str = str(sample.transition)\n",
    "        \n",
    "        # --- ESTO ES EL INPUT DE LA RED NEURONAL ---\n",
    "        # Usamos el método state_to_feats que ya tiene tu clase Sample.\n",
    "        # Esto extrae las palabras y tags de la Pila y el Búfer.\n",
    "        nn_input = sample.state_to_feats(nbuffer_feats=2, nstack_feats=2)\n",
    "        \n",
    "        # Imprimimos la fila\n",
    "        # stack_str[-25:] corta el string si es muy largo para que quepa\n",
    "        print(f\"{i:<4} | {stack_str[-25:]:<25} | {buffer_str:<25} | {action_str:<15} | {nn_input}\")\n",
    "\n",
    "        # Avanzamos la simulación aplicando la transición\n",
    "        arc_eager.apply_transition(config, sample.transition)-\n",
    "\n",
    "    # 4. Comparación Final\n",
    "    print(\"-\" * 120)\n",
    "    print(\"Comparación de Arcos (Dependencias):\")\n",
    "    \n",
    "    # Usamos el método gold_arcs que ya tienes en algorithm.py\n",
    "    gold_arcs = arc_eager.gold_arcs(example_sent)\n",
    "    generated_arcs = config.A # Los arcos que generó nuestra simulación\n",
    "    \n",
    "    print(f\"Total arcos Gold (Reales): {len(gold_arcs)}\")\n",
    "    print(f\"Total arcos Generados: {len(generated_arcs)}\")\n",
    "    \n",
    "    if gold_arcs == generated_arcs:\n",
    "        print(\"\\n✅ ¡ÉXITO! El oráculo reconstruyó el árbol perfectamente.\")\n",
    "        print(\"Los inputs mostrados arriba son correctos para entrenar la red.\")\n",
    "    else:\n",
    "        print(\"\\n❌ ERROR: Los árboles no coinciden.\")\n",
    "        print(\"Arcos faltantes:\", gold_arcs - generated_arcs)\n",
    "        print(\"Arcos sobrantes:\", generated_arcs - gold_arcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abcffb-8956-4281-8e5d-20904150e300",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing for Multi-Output Model\n",
    "\n",
    "Before building the neural network, we need to load the processed training data and prepare it for the specific multi-output architecture required by the assignment.\n",
    "\n",
    "This block performs the following critical steps:\n",
    "\n",
    "1.  **Load Numerical Data:** It reads the `training_data.npz` file created in the previous phase. This file contains the feature matrix `X` (words and tags encoded as integers) and the target vectors. Crucially, we now load **two sets of targets**:\n",
    "    * `y_act`: The IDs for the transition actions (SHIFT, REDUCE, etc.).\n",
    "    * `y_dep`: The IDs for the dependency labels (nsubj, det, etc.). This is required because our network will have two separate output heads to predict these simultaneously.\n",
    "\n",
    "2.  **Load Vocabularies:** It retrieves the `vocabs.pkl` dictionaries to determine the input dimensions (number of unique words and tags) and output dimensions (number of unique actions and labels) needed for the network layers.\n",
    "\n",
    "3.  **Train/Validation Split:** The data is split into a training set (90%) and a validation set (10%). This allows us to monitor the model's generalization performance and use Early Stopping to prevent overfitting.\n",
    "\n",
    "4.  **Feature Separation:** The input matrix `X` currently contains words and POS tags concatenated together (e.g., `[Word_S2, Word_S1... Tag_S2, Tag_S1...]`). The code slices this matrix into two separate arrays:\n",
    "    * `X_train_words`: Contains only the word features.\n",
    "    * `X_train_tags`: Contains only the POS tag features.\n",
    "    This separation is essential because our neural network architecture uses **separate Embedding layers** for words and tags, allowing the model to learn distinct vector representations for each type of information before combining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f58fe69-f6c9-4332-9264-1929de6953c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Loading Training Data and Vocabularies ---\n",
      "Training samples: 73063\n",
      "Validation samples: 8119\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import pickle\n",
    "\n",
    "# --- 1. LOAD PREPARED DATA ---\n",
    "print(\"--- STEP 1: Loading Training Data and Vocabularies ---\")\n",
    "\n",
    "try:\n",
    "    data = np.load(\"training_data.npz\")\n",
    "    X_train_full = data['X']      # Shape: (Num_Samples, 8) -> 4 words + 4 tags\n",
    "    y_train_act_full = data['y_act']   # Shape: (Num_Samples,) -> Action IDs\n",
    "    y_train_dep_full = data['y_dep']   # Shape: (Num_Samples,) -> Dependency IDs\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'training_data.npz' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Load vocabularies\n",
    "try:\n",
    "    with open(\"vocabs.pkl\", \"rb\") as f:\n",
    "        words_vocab, upos_vocab, actions_vocab, deprels_vocab = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'vocabs.pkl' not found.\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Splitting ---\n",
    "split_idx = int(len(X_train_full) * 0.9)\n",
    "\n",
    "# Inputs\n",
    "X_train, X_val = X_train_full[:split_idx], X_train_full[split_idx:]\n",
    "\n",
    "# Outputs (We need TWO sets of targets now)\n",
    "y_train_act, y_val_act = y_train_act_full[:split_idx], y_train_act_full[split_idx:]\n",
    "y_train_dep, y_val_dep = y_train_dep_full[:split_idx], y_train_dep_full[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "\n",
    "# --- 2. SEPARATE INPUTS (Words vs Tags) ---\n",
    "# X contains [Word_S2, Word_S1, Word_B1, Word_B2, Tag_S2, Tag_S1, Tag_B1, Tag_B2]\n",
    "num_features_total = X_train.shape[1]\n",
    "num_word_feats = num_features_total // 2 \n",
    "\n",
    "X_train_words = X_train[:, :num_word_feats]\n",
    "X_train_tags  = X_train[:, num_word_feats:]\n",
    "\n",
    "X_val_words = X_val[:, :num_word_feats]\n",
    "X_val_tags  = X_val[:, num_word_feats:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1520c2-e190-4392-8de9-13f06e391bda",
   "metadata": {},
   "source": [
    "## 2. Building the Multi-Output Neural Network Architecture\n",
    "\n",
    "This section defines the core neural network architecture that we will use as a baseline for our dependency parser. The design follows the specifications for a multi-output classifier that simultaneously predicts both the parser action and the dependency label.\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "We use the Keras **Functional API** to build a flexible model with two separate input branches and two separate output heads.\n",
    "\n",
    "1.  **Dual Inputs:**\n",
    "    * **`input_words`**: Takes the integer IDs of the words extracted from the stack and buffer.\n",
    "    * **`input_tags`**: Takes the integer IDs of the POS tags corresponding to those words.\n",
    "    * *Why separate inputs?* Words and POS tags belong to very different vocabularies (thousands of words vs. ~17 tags). Separating them allows us to learn distinct, specialized vector representations (embeddings) for each type of feature.\n",
    "\n",
    "2.  **Embedding Layers:**\n",
    "    * **`embed_words` & `embed_tags`**: These layers transform sparse integer IDs into dense vectors of fixed size (`WORD_EMBED_DIM` and `POS_EMBED_DIM`). This allows the network to learn semantic relationships between words and tags.\n",
    "\n",
    "3.  **Feature Merging:**\n",
    "    * The embeddings are flattened and then **concatenated** into a single long feature vector. This combined representation captures the full state of the parser (stack + buffer content) at a given moment.\n",
    "\n",
    "4.  **Shared Hidden Layer:**\n",
    "    * **`hidden_shared`**: A dense layer with ReLU activation. It processes the combined features to learn abstract patterns relevant to *both* prediction tasks.\n",
    "    * **`Dropout`**: A regularization layer is added to prevent overfitting by randomly dropping connections during training.\n",
    "\n",
    "5.  **Dual Outputs (Two Heads):**\n",
    "    * **`action_output`**: A Softmax layer that outputs a probability distribution over the possible transition actions (SHIFT, REDUCE, LEFT-ARC, RIGHT-ARC).\n",
    "    * **`label_output`**: A separate Softmax layer that outputs probabilities for the dependency labels (e.g., nsubj, det, punct). This design allows the model to specialize in structural decisions and labeling decisions independently while sharing the underlying feature extraction logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59a10abc-f193-4dca-9a92-58fcf048c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1 (Actions): 4 classes\n",
      "Output 2 (Labels): 44 classes\n",
      "--- STEP 2: Building Multi-Output Neural Network ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:19:37.202687: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ArcEager_MultiOutput_Parser\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ArcEager_MultiOutput_Parser\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,936</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,900</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_shared[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,444</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │    \u001b[38;5;34m219,936\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m210\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m16,900\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_shared[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m404\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m4,444\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">241,894</span> (944.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m241,894\u001b[0m (944.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">241,894</span> (944.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m241,894\u001b[0m (944.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3. DEFINE HYPERPARAMETERS ---\n",
    "WORD_EMBED_DIM = 32\n",
    "POS_EMBED_DIM = 10\n",
    "HIDDEN_UNITS = 100\n",
    "\n",
    "NUM_WORDS = len(words_vocab) + 1\n",
    "NUM_TAGS = len(upos_vocab) + 1\n",
    "NUM_ACTIONS = len(actions_vocab)  # Output 1 size (e.g., 4: SHIFT, REDUCE, LA, RA)\n",
    "NUM_DEPRELS = len(deprels_vocab)  # Output 2 size (e.g., 44 dependency labels)\n",
    "\n",
    "print(f\"Output 1 (Actions): {NUM_ACTIONS} classes\")\n",
    "print(f\"Output 2 (Labels): {NUM_DEPRELS} classes\")\n",
    "\n",
    "\n",
    "# --- 4. BUILD THE MODEL (Multi-Output) ---\n",
    "print(\"--- STEP 2: Building Multi-Output Neural Network ---\")\n",
    "\n",
    "# A. Input Layers\n",
    "input_words = layers.Input(shape=(num_word_feats,), name=\"input_words\")\n",
    "input_tags  = layers.Input(shape=(num_word_feats,), name=\"input_tags\")\n",
    "\n",
    "# B. Embedding Layers\n",
    "embed_words = layers.Embedding(input_dim=NUM_WORDS, output_dim=WORD_EMBED_DIM, name=\"embed_words\")(input_words)\n",
    "embed_tags  = layers.Embedding(input_dim=NUM_TAGS, output_dim=POS_EMBED_DIM, name=\"embed_tags\")(input_tags)\n",
    "\n",
    "# C. Flatten & Concatenate\n",
    "flat_words = layers.Flatten()(embed_words)\n",
    "flat_tags  = layers.Flatten()(embed_tags)\n",
    "merged = layers.Concatenate(name=\"concat_features\")([flat_words, flat_tags])\n",
    "\n",
    "# D. Shared Hidden Layers\n",
    "# This layer learns features relevant for BOTH tasks (action and label prediction)\n",
    "hidden = layers.Dense(HIDDEN_UNITS, activation='relu', name=\"hidden_shared\")(merged)\n",
    "hidden = layers.Dropout(0.2)(hidden)\n",
    "\n",
    "# E. Output Layers (The Two Heads)\n",
    "# Head 1: Predicts the transition action (SHIFT, REDUCE, etc.)\n",
    "output_action = layers.Dense(NUM_ACTIONS, activation='softmax', name=\"action_output\")(hidden)\n",
    "\n",
    "# Head 2: Predicts the dependency label (nsubj, det, etc.)\n",
    "output_label = layers.Dense(NUM_DEPRELS, activation='softmax', name=\"label_output\")(hidden)\n",
    "\n",
    "# Create Model with 2 inputs and 2 outputs\n",
    "model = models.Model(\n",
    "    inputs=[input_words, input_tags], \n",
    "    outputs=[output_action, output_label], \n",
    "    name=\"ArcEager_MultiOutput_Parser\"\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a4bb8-28e0-4e7c-9e63-e354104a7122",
   "metadata": {},
   "source": [
    "## 3. Compilation and Training of the Multi-Output Model\n",
    "\n",
    "This final step configures the learning process and executes the training loop for our dependency parser model.\n",
    "\n",
    "### Compilation Configuration\n",
    "\n",
    "We use the `.compile()` method to specify how the model should learn. Since our model has two distinct outputs (`action_output` and `label_output`), we must define the loss function and metrics for *each* of them.\n",
    "\n",
    "1.  **Loss Functions:**\n",
    "    * We assign `sparse_categorical_crossentropy` to both outputs.\n",
    "    * This loss function is ideal because our targets (`y_train_act` and `y_train_dep`) are encoded as integers (IDs), not one-hot vectors. It efficiently calculates the error between the predicted probability distribution and the true integer class label.\n",
    "\n",
    "2.  **Metrics:**\n",
    "    * We track `accuracy` for both outputs. This gives us a clear, human-readable measure of how often the model correctly predicts the transition action and the dependency label.\n",
    "\n",
    "3.  **Optimizer:**\n",
    "    * We use the `adam` optimizer, a standard and robust choice for training deep learning models that automatically adapts the learning rate.\n",
    "\n",
    "### Training Process\n",
    "\n",
    "The `.fit()` method launches the training loop. We must provide the data in a format that matches our model's multi-input, multi-output structure:\n",
    "\n",
    "* **`x` (Inputs):** A list containing the two input arrays: `[X_train_words, X_train_tags]`. Keras maps these to the `input_words` and `input_tags` layers respectively.\n",
    "* **`y` (Targets):** A list containing the two target arrays: `[y_train_act, y_train_dep]`. These correspond to the `action_output` and `label_output` layers.\n",
    "* **`validation_data`:** We provide the validation sets in the exact same structure `([Inputs], [Targets])` to evaluate the model on unseen data after each epoch.\n",
    "\n",
    "After training completes, the model is saved to `parser_model_multi.keras`, preserving the architecture, weights, and training configuration for future use or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85edb681-5587-48ae-8683-287c03f37b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 3: Training the Model ---\n",
      "Epoch 1/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.8223 - action_output_loss: 0.4640 - label_output_accuracy: 0.7633 - label_output_loss: 0.8593 - loss: 1.3231 - val_action_output_accuracy: 0.8671 - val_action_output_loss: 0.3514 - val_label_output_accuracy: 0.8316 - val_label_output_loss: 0.4959 - val_loss: 0.8480\n",
      "Epoch 2/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.8958 - action_output_loss: 0.2802 - label_output_accuracy: 0.8608 - label_output_loss: 0.4267 - loss: 0.7069 - val_action_output_accuracy: 0.8632 - val_action_output_loss: 0.3559 - val_label_output_accuracy: 0.8436 - val_label_output_loss: 0.4461 - val_loss: 0.8027\n",
      "Epoch 3/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9245 - action_output_loss: 0.2079 - label_output_accuracy: 0.8957 - label_output_loss: 0.3193 - loss: 0.5273 - val_action_output_accuracy: 0.8632 - val_action_output_loss: 0.3758 - val_label_output_accuracy: 0.8467 - val_label_output_loss: 0.4411 - val_loss: 0.8176\n",
      "Epoch 4/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9407 - action_output_loss: 0.1635 - label_output_accuracy: 0.9198 - label_output_loss: 0.2448 - loss: 0.4084 - val_action_output_accuracy: 0.8561 - val_action_output_loss: 0.4084 - val_label_output_accuracy: 0.8443 - val_label_output_loss: 0.4782 - val_loss: 0.8875\n",
      "Epoch 5/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9515 - action_output_loss: 0.1355 - label_output_accuracy: 0.9366 - label_output_loss: 0.2006 - loss: 0.3362 - val_action_output_accuracy: 0.8550 - val_action_output_loss: 0.4443 - val_label_output_accuracy: 0.8411 - val_label_output_loss: 0.5076 - val_loss: 0.9527\n",
      "Epoch 6/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9590 - action_output_loss: 0.1144 - label_output_accuracy: 0.9487 - label_output_loss: 0.1630 - loss: 0.2773 - val_action_output_accuracy: 0.8527 - val_action_output_loss: 0.4855 - val_label_output_accuracy: 0.8415 - val_label_output_loss: 0.5542 - val_loss: 1.0407\n",
      "Epoch 7/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9651 - action_output_loss: 0.0982 - label_output_accuracy: 0.9569 - label_output_loss: 0.1369 - loss: 0.2351 - val_action_output_accuracy: 0.8517 - val_action_output_loss: 0.5290 - val_label_output_accuracy: 0.8358 - val_label_output_loss: 0.5963 - val_loss: 1.1262\n",
      "Epoch 8/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9688 - action_output_loss: 0.0867 - label_output_accuracy: 0.9637 - label_output_loss: 0.1151 - loss: 0.2018 - val_action_output_accuracy: 0.8521 - val_action_output_loss: 0.5578 - val_label_output_accuracy: 0.8364 - val_label_output_loss: 0.6349 - val_loss: 1.1936\n",
      "Epoch 9/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9726 - action_output_loss: 0.0770 - label_output_accuracy: 0.9680 - label_output_loss: 0.1004 - loss: 0.1772 - val_action_output_accuracy: 0.8506 - val_action_output_loss: 0.5983 - val_label_output_accuracy: 0.8385 - val_label_output_loss: 0.6825 - val_loss: 1.2818\n",
      "Epoch 10/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9758 - action_output_loss: 0.0674 - label_output_accuracy: 0.9716 - label_output_loss: 0.0875 - loss: 0.1549 - val_action_output_accuracy: 0.8487 - val_action_output_loss: 0.6373 - val_label_output_accuracy: 0.8342 - val_label_output_loss: 0.7362 - val_loss: 1.3747\n",
      "--- STEP 4: Saving Model ---\n",
      "Model saved to 'parser_model_multi.keras'\n"
     ]
    }
   ],
   "source": [
    "# --- 5. COMPILE AND TRAIN ---\n",
    "print(\"--- STEP 3: Training the Model ---\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    # We define a loss function for EACH output layer (by name or order)\n",
    "    loss={\n",
    "        \"action_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"label_output\": \"sparse_categorical_crossentropy\"\n",
    "    },\n",
    "    # We calculate accuracy for each output separately\n",
    "    metrics={\n",
    "        \"action_output\": [\"accuracy\"],\n",
    "        \"label_output\": [\"accuracy\"]\n",
    "    },\n",
    "    # Optional: Weigh the losses. Maybe action is more critical than label?\n",
    "    # loss_weights={\"action_output\": 1.0, \"label_output\": 1.0} \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "# Note: 'y' is now a LIST of targets [actions, labels] corresponding to the outputs\n",
    "history = model.fit(\n",
    "    x=[X_train_words, X_train_tags],\n",
    "    y=[y_train_act, y_train_dep],  \n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_val_words, X_val_tags], [y_val_act, y_val_dep]),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- 6. SAVE THE MODEL ---\n",
    "print(\"--- STEP 4: Saving Model ---\")\n",
    "model.save(\"parser_model_multi.keras\")\n",
    "print(\"Model saved to 'parser_model_multi.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf1d5b-80de-4d69-a79e-7e60dc99123c",
   "metadata": {},
   "source": [
    "## 4. Model Experimentation Loop (Hyperparameter Tuning)\n",
    "\n",
    "This section implements the core of our experimental strategy. Instead of training a single model, we define a systematic process to explore different architectural configurations and hyperparameters to find the best performing dependency parser.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "1.  **`build_and_train_parser` Function:**\n",
    "    This reusable function acts as a \"model factory\". It encapsulates the entire lifecycle of a single experiment:\n",
    "    * **Architecture Construction:** It dynamically builds a Keras Functional API model based on the provided parameters (embedding dimensions, hidden units, dropout rate). It sets up the dual inputs (words, tags) and dual outputs (actions, labels).\n",
    "    * **Compilation:** It configures the optimizer (Adam with variablme learning rate) and assigns the specific loss functions (`sparse_categorical_crossentropy`) and metrics to each output head.\n",
    "    * **Training with Early Stopping:** It trains the model while monitoring the validation accuracy of the *action* prediction (`val_action_output_accuracy`). If this metric stops improving for 3 epochs, training stops automatically, and the weights from the best epoch are restored. This ensures we always keep the most generalizable version of the model.\n",
    "\n",
    "2.  **Hyperparameter Grid (`hyperparameter_grid`):**\n",
    "    We define a list of dictionaries, where each dictionary represents a unique experiment configuration. We test variations in:\n",
    "    * `word_embed_dim` & `pos_embed_dim`: To test if richer representations improve performance.\n",
    "    * `hidden_units`: To test the capacity of the shared layer.\n",
    "    * `learning_rate`: To find the optimal convergence speed.\n",
    "    * `batch_size`: To balance gradient stability and training speed.\n",
    "    * `dropout_rate`: To test different regularization strengths against overfitting.\n",
    "\n",
    "3.  **Execution Loop:**\n",
    "    The code iterates through the grid, training a new model for each configuration. It tracks the best performing model based on its validation action accuracy.\n",
    "\n",
    "4.  **Model Selection and Saving:**\n",
    "    At the end of the loop, the script identifies the \"champion\" model—the one with the highest validation accuracy on the action task—and saves it to disk (`.keras` format) for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba5b103d-9c5b-47a3-8892-8306866d456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Search over 6 models...\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: Base_Model\n",
      "Params: WordEmb=32, PosEmb=10, Hidden=100, LR=0.001, Drop=0.2, Batch=32\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Base_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Base_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,936</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,900</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_shared[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,444</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │    \u001b[38;5;34m219,936\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m210\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m16,900\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_shared[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m404\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m4,444\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">241,894</span> (944.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m241,894\u001b[0m (944.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">241,894</span> (944.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m241,894\u001b[0m (944.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - action_output_accuracy: 0.8203 - action_output_loss: 0.4662 - label_output_accuracy: 0.7620 - label_output_loss: 0.8524 - loss: 1.3187 - val_action_output_accuracy: 0.8619 - val_action_output_loss: 0.3512 - val_label_output_accuracy: 0.8336 - val_label_output_loss: 0.4895 - val_loss: 0.8414\n",
      "Epoch 2/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.8953 - action_output_loss: 0.2822 - label_output_accuracy: 0.8598 - label_output_loss: 0.4278 - loss: 0.7101 - val_action_output_accuracy: 0.8683 - val_action_output_loss: 0.3502 - val_label_output_accuracy: 0.8481 - val_label_output_loss: 0.4366 - val_loss: 0.7874\n",
      "Epoch 3/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9243 - action_output_loss: 0.2065 - label_output_accuracy: 0.8961 - label_output_loss: 0.3219 - loss: 0.5286 - val_action_output_accuracy: 0.8692 - val_action_output_loss: 0.3656 - val_label_output_accuracy: 0.8540 - val_label_output_loss: 0.4345 - val_loss: 0.8008\n",
      "Epoch 4/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9419 - action_output_loss: 0.1627 - label_output_accuracy: 0.9193 - label_output_loss: 0.2509 - loss: 0.4137 - val_action_output_accuracy: 0.8582 - val_action_output_loss: 0.4100 - val_label_output_accuracy: 0.8497 - val_label_output_loss: 0.4564 - val_loss: 0.8671\n",
      "Epoch 5/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9522 - action_output_loss: 0.1338 - label_output_accuracy: 0.9363 - label_output_loss: 0.2004 - loss: 0.3344 - val_action_output_accuracy: 0.8547 - val_action_output_loss: 0.4389 - val_label_output_accuracy: 0.8447 - val_label_output_loss: 0.4916 - val_loss: 0.9312\n",
      "Epoch 6/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9603 - action_output_loss: 0.1124 - label_output_accuracy: 0.9472 - label_output_loss: 0.1656 - loss: 0.2781 - val_action_output_accuracy: 0.8497 - val_action_output_loss: 0.4817 - val_label_output_accuracy: 0.8446 - val_label_output_loss: 0.5427 - val_loss: 1.0252\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "--- Training Finished for Base_Model ---\n",
      "Result Base_Model: Best Validation Action Accuracy = 0.8692\n",
      " >> New Best Model Found! (Previous best: 0.0000)\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: Large_Embeddings_HigherDrop\n",
      "Params: WordEmb=64, PosEmb=20, Hidden=200, LR=0.001, Drop=0.3, Batch=64\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Large_Embeddings_HigherDrop\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Large_Embeddings_HigherDrop\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">439,872</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">336</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">67,400</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_shared[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">804</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,844</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │    \u001b[38;5;34m439,872\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │        \u001b[38;5;34m420\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m336\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │     \u001b[38;5;34m67,400\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_shared[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m804\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m8,844\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">517,340</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m517,340\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">517,340</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m517,340\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - action_output_accuracy: 0.8249 - action_output_loss: 0.4588 - label_output_accuracy: 0.7694 - label_output_loss: 0.8310 - loss: 1.2900 - val_action_output_accuracy: 0.8621 - val_action_output_loss: 0.3482 - val_label_output_accuracy: 0.8391 - val_label_output_loss: 0.4727 - val_loss: 0.8214\n",
      "Epoch 2/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - action_output_accuracy: 0.9024 - action_output_loss: 0.2636 - label_output_accuracy: 0.8696 - label_output_loss: 0.3992 - loss: 0.6628 - val_action_output_accuracy: 0.8702 - val_action_output_loss: 0.3481 - val_label_output_accuracy: 0.8507 - val_label_output_loss: 0.4255 - val_loss: 0.7740\n",
      "Epoch 3/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - action_output_accuracy: 0.9324 - action_output_loss: 0.1864 - label_output_accuracy: 0.9082 - label_output_loss: 0.2861 - loss: 0.4726 - val_action_output_accuracy: 0.8726 - val_action_output_loss: 0.3557 - val_label_output_accuracy: 0.8520 - val_label_output_loss: 0.4311 - val_loss: 0.7873\n",
      "Epoch 4/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - action_output_accuracy: 0.9508 - action_output_loss: 0.1396 - label_output_accuracy: 0.9337 - label_output_loss: 0.2126 - loss: 0.3521 - val_action_output_accuracy: 0.8643 - val_action_output_loss: 0.3998 - val_label_output_accuracy: 0.8475 - val_label_output_loss: 0.4582 - val_loss: 0.8584\n",
      "Epoch 5/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - action_output_accuracy: 0.9605 - action_output_loss: 0.1117 - label_output_accuracy: 0.9492 - label_output_loss: 0.1625 - loss: 0.2743 - val_action_output_accuracy: 0.8591 - val_action_output_loss: 0.4397 - val_label_output_accuracy: 0.8473 - val_label_output_loss: 0.5085 - val_loss: 0.9484\n",
      "Epoch 6/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - action_output_accuracy: 0.9683 - action_output_loss: 0.0909 - label_output_accuracy: 0.9594 - label_output_loss: 0.1284 - loss: 0.2194 - val_action_output_accuracy: 0.8585 - val_action_output_loss: 0.4863 - val_label_output_accuracy: 0.8486 - val_label_output_loss: 0.5455 - val_loss: 1.0321\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "--- Training Finished for Large_Embeddings_HigherDrop ---\n",
      "Result Large_Embeddings_HigherDrop: Best Validation Action Accuracy = 0.8726\n",
      " >> New Best Model Found! (Previous best: 0.8692)\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: Base_SlowLR\n",
      "Params: WordEmb=32, PosEmb=10, Hidden=100, LR=0.0005, Drop=0.2, Batch=32\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Base_SlowLR\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Base_SlowLR\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,936</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,900</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_shared[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,444</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │    \u001b[38;5;34m219,936\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m210\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m16,900\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_shared[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m404\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m4,444\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">241,894</span> (944.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m241,894\u001b[0m (944.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">241,894</span> (944.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m241,894\u001b[0m (944.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - action_output_accuracy: 0.7932 - action_output_loss: 0.5337 - label_output_accuracy: 0.7090 - label_output_loss: 1.1160 - loss: 1.6494 - val_action_output_accuracy: 0.8522 - val_action_output_loss: 0.3840 - val_label_output_accuracy: 0.8134 - val_label_output_loss: 0.6015 - val_loss: 0.9862\n",
      "Epoch 2/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.8739 - action_output_loss: 0.3359 - label_output_accuracy: 0.8310 - label_output_loss: 0.5491 - loss: 0.8851 - val_action_output_accuracy: 0.8590 - val_action_output_loss: 0.3607 - val_label_output_accuracy: 0.8341 - val_label_output_loss: 0.4965 - val_loss: 0.8580\n",
      "Epoch 3/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9015 - action_output_loss: 0.2657 - label_output_accuracy: 0.8624 - label_output_loss: 0.4321 - loss: 0.6979 - val_action_output_accuracy: 0.8614 - val_action_output_loss: 0.3671 - val_label_output_accuracy: 0.8370 - val_label_output_loss: 0.4657 - val_loss: 0.8335\n",
      "Epoch 4/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9210 - action_output_loss: 0.2195 - label_output_accuracy: 0.8857 - label_output_loss: 0.3607 - loss: 0.5802 - val_action_output_accuracy: 0.8569 - val_action_output_loss: 0.3858 - val_label_output_accuracy: 0.8409 - val_label_output_loss: 0.4613 - val_loss: 0.8478\n",
      "Epoch 5/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9324 - action_output_loss: 0.1885 - label_output_accuracy: 0.9039 - label_output_loss: 0.3053 - loss: 0.4939 - val_action_output_accuracy: 0.8553 - val_action_output_loss: 0.4100 - val_label_output_accuracy: 0.8422 - val_label_output_loss: 0.4718 - val_loss: 0.8825\n",
      "Epoch 6/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9441 - action_output_loss: 0.1612 - label_output_accuracy: 0.9189 - label_output_loss: 0.2625 - loss: 0.4237 - val_action_output_accuracy: 0.8558 - val_action_output_loss: 0.4328 - val_label_output_accuracy: 0.8436 - val_label_output_loss: 0.4801 - val_loss: 0.9136\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "--- Training Finished for Base_SlowLR ---\n",
      "Result Base_SlowLR: Best Validation Action Accuracy = 0.8614\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: Small_Fast_Model\n",
      "Params: WordEmb=16, PosEmb=5, Hidden=50, LR=0.001, Drop=0.1, Batch=128\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Small_Fast_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Small_Fast_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">109,968</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,250</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_shared[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,244</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │    \u001b[38;5;34m109,968\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │        \u001b[38;5;34m105\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │      \u001b[38;5;34m4,250\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ hidden_shared[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m204\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m2,244\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,771</span> (456.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m116,771\u001b[0m (456.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,771</span> (456.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m116,771\u001b[0m (456.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/15\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - action_output_accuracy: 0.7553 - action_output_loss: 0.6349 - label_output_accuracy: 0.6377 - label_output_loss: 1.4716 - loss: 2.1067 - val_action_output_accuracy: 0.8438 - val_action_output_loss: 0.4169 - val_label_output_accuracy: 0.7763 - val_label_output_loss: 0.7725 - val_loss: 1.1945\n",
      "Epoch 2/15\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - action_output_accuracy: 0.8525 - action_output_loss: 0.3916 - label_output_accuracy: 0.7994 - label_output_loss: 0.6822 - loss: 1.0739 - val_action_output_accuracy: 0.8512 - val_action_output_loss: 0.3826 - val_label_output_accuracy: 0.8198 - val_label_output_loss: 0.5648 - val_loss: 0.9519\n",
      "Epoch 3/15\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - action_output_accuracy: 0.8796 - action_output_loss: 0.3241 - label_output_accuracy: 0.8354 - label_output_loss: 0.5295 - loss: 0.8535 - val_action_output_accuracy: 0.8542 - val_action_output_loss: 0.3840 - val_label_output_accuracy: 0.8290 - val_label_output_loss: 0.5110 - val_loss: 0.8994\n",
      "Epoch 4/15\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - action_output_accuracy: 0.8989 - action_output_loss: 0.2775 - label_output_accuracy: 0.8570 - label_output_loss: 0.4532 - loss: 0.7308 - val_action_output_accuracy: 0.8540 - val_action_output_loss: 0.3911 - val_label_output_accuracy: 0.8322 - val_label_output_loss: 0.4916 - val_loss: 0.8868\n",
      "Epoch 5/15\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - action_output_accuracy: 0.9122 - action_output_loss: 0.2442 - label_output_accuracy: 0.8716 - label_output_loss: 0.4022 - loss: 0.6464 - val_action_output_accuracy: 0.8537 - val_action_output_loss: 0.3996 - val_label_output_accuracy: 0.8385 - val_label_output_loss: 0.4803 - val_loss: 0.8838\n",
      "Epoch 6/15\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - action_output_accuracy: 0.9201 - action_output_loss: 0.2184 - label_output_accuracy: 0.8856 - label_output_loss: 0.3593 - loss: 0.5777 - val_action_output_accuracy: 0.8511 - val_action_output_loss: 0.4200 - val_label_output_accuracy: 0.8399 - val_label_output_loss: 0.4832 - val_loss: 0.9069\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "--- Training Finished for Small_Fast_Model ---\n",
      "Result Small_Fast_Model: Best Validation Action Accuracy = 0.8542\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: High_Dropout_Regularization\n",
      "Params: WordEmb=64, PosEmb=10, Hidden=150, LR=0.001, Drop=0.4, Batch=32\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"High_Dropout_Regularization\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"High_Dropout_Regularization\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">439,872</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">296</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">44,550</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_shared[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">604</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,644</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │    \u001b[38;5;34m439,872\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m210\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m296\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │     \u001b[38;5;34m44,550\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_shared[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m604\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m6,644\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">491,880</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m491,880\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">491,880</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m491,880\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - action_output_accuracy: 0.8223 - action_output_loss: 0.4641 - label_output_accuracy: 0.7625 - label_output_loss: 0.8434 - loss: 1.3078 - val_action_output_accuracy: 0.8702 - val_action_output_loss: 0.3372 - val_label_output_accuracy: 0.8367 - val_label_output_loss: 0.4726 - val_loss: 0.8105\n",
      "Epoch 2/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - action_output_accuracy: 0.8987 - action_output_loss: 0.2728 - label_output_accuracy: 0.8659 - label_output_loss: 0.4174 - loss: 0.6899 - val_action_output_accuracy: 0.8689 - val_action_output_loss: 0.3452 - val_label_output_accuracy: 0.8475 - val_label_output_loss: 0.4351 - val_loss: 0.7810\n",
      "Epoch 3/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - action_output_accuracy: 0.9281 - action_output_loss: 0.1988 - label_output_accuracy: 0.9019 - label_output_loss: 0.3041 - loss: 0.5030 - val_action_output_accuracy: 0.8671 - val_action_output_loss: 0.3647 - val_label_output_accuracy: 0.8522 - val_label_output_loss: 0.4395 - val_loss: 0.8051\n",
      "Epoch 4/15\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - action_output_accuracy: 0.9450 - action_output_loss: 0.1525 - label_output_accuracy: 0.9265 - label_output_loss: 0.2327 - loss: 0.3852 - val_action_output_accuracy: 0.8572 - val_action_output_loss: 0.4118 - val_label_output_accuracy: 0.8464 - val_label_output_loss: 0.4761 - val_loss: 0.8887\n",
      "Epoch 4: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Training Finished for High_Dropout_Regularization ---\n",
      "Result High_Dropout_Regularization: Best Validation Action Accuracy = 0.8702\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: Wide_Hidden_Layer\n",
      "Params: WordEmb=32, PosEmb=10, Hidden=300, LR=0.001, Drop=0.2, Batch=64\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Wide_Hidden_Layer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Wide_Hidden_Layer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,936</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,700</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_shared[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,244</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │    \u001b[38;5;34m219,936\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m210\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │     \u001b[38;5;34m50,700\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_shared[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │      \u001b[38;5;34m1,204\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │     \u001b[38;5;34m13,244\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">285,294</span> (1.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m285,294\u001b[0m (1.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">285,294</span> (1.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m285,294\u001b[0m (1.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - action_output_accuracy: 0.8240 - action_output_loss: 0.4612 - label_output_accuracy: 0.7704 - label_output_loss: 0.8298 - loss: 1.2911 - val_action_output_accuracy: 0.8672 - val_action_output_loss: 0.3444 - val_label_output_accuracy: 0.8346 - val_label_output_loss: 0.4793 - val_loss: 0.8242\n",
      "Epoch 2/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - action_output_accuracy: 0.9006 - action_output_loss: 0.2636 - label_output_accuracy: 0.8669 - label_output_loss: 0.4037 - loss: 0.6674 - val_action_output_accuracy: 0.8667 - val_action_output_loss: 0.3368 - val_label_output_accuracy: 0.8538 - val_label_output_loss: 0.4311 - val_loss: 0.7683\n",
      "Epoch 3/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - action_output_accuracy: 0.9292 - action_output_loss: 0.1934 - label_output_accuracy: 0.9023 - label_output_loss: 0.2981 - loss: 0.4916 - val_action_output_accuracy: 0.8676 - val_action_output_loss: 0.3615 - val_label_output_accuracy: 0.8511 - val_label_output_loss: 0.4273 - val_loss: 0.7891\n",
      "Epoch 4/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - action_output_accuracy: 0.9478 - action_output_loss: 0.1463 - label_output_accuracy: 0.9289 - label_output_loss: 0.2241 - loss: 0.3705 - val_action_output_accuracy: 0.8677 - val_action_output_loss: 0.3964 - val_label_output_accuracy: 0.8537 - val_label_output_loss: 0.4526 - val_loss: 0.8492\n",
      "Epoch 5/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - action_output_accuracy: 0.9582 - action_output_loss: 0.1174 - label_output_accuracy: 0.9467 - label_output_loss: 0.1730 - loss: 0.2903 - val_action_output_accuracy: 0.8623 - val_action_output_loss: 0.4306 - val_label_output_accuracy: 0.8479 - val_label_output_loss: 0.5003 - val_loss: 0.9312\n",
      "Epoch 6/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - action_output_accuracy: 0.9664 - action_output_loss: 0.0962 - label_output_accuracy: 0.9573 - label_output_loss: 0.1373 - loss: 0.2334 - val_action_output_accuracy: 0.8577 - val_action_output_loss: 0.4802 - val_label_output_accuracy: 0.8458 - val_label_output_loss: 0.5313 - val_loss: 1.0117\n",
      "Epoch 7/15\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - action_output_accuracy: 0.9722 - action_output_loss: 0.0799 - label_output_accuracy: 0.9655 - label_output_loss: 0.1106 - loss: 0.1905 - val_action_output_accuracy: 0.8569 - val_action_output_loss: 0.5086 - val_label_output_accuracy: 0.8411 - val_label_output_loss: 0.5800 - val_loss: 1.0885\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "--- Training Finished for Wide_Hidden_Layer ---\n",
      "Result Wide_Hidden_Layer: Best Validation Action Accuracy = 0.8677\n",
      "\n",
      "============================================================\n",
      "SEARCH COMPLETE\n",
      "Best Model: 'Large_Embeddings_HigherDrop' with Action Accuracy: 0.8726\n",
      "============================================================\n",
      "\n",
      "Saving best model to: Large_Embeddings_HigherDrop_best.keras\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_and_train_parser(\n",
    "    # Input Data\n",
    "    X_train_words, X_train_tags, y_train_act, y_train_dep,\n",
    "    X_val_words, X_val_tags, y_val_act, y_val_dep,\n",
    "    # Fixed Dimensions (Vocabularies)\n",
    "    num_words, num_tags, num_actions, num_deprels,\n",
    "    # Hyperparameters (Variables)\n",
    "    word_embed_dim=32,\n",
    "    pos_embed_dim=10,\n",
    "    hidden_units=100,\n",
    "    learning_rate=0.001,\n",
    "    dropout_rate=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    model_name=\"Parser_Model\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds, compiles, and trains a multi-output neural network for dependency parsing.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING MODEL: {model_name}\")\n",
    "    print(f\"Params: WordEmb={word_embed_dim}, PosEmb={pos_embed_dim}, Hidden={hidden_units}, LR={learning_rate}, Drop={dropout_rate}, Batch={batch_size}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # --- 1. Architecture ---\n",
    "    \n",
    "    # Input Layers\n",
    "    # Shape is determined by the number of features selected (e.g., 2 stack + 2 buffer = 4)\n",
    "    input_words = layers.Input(shape=(X_train_words.shape[1],), name=\"input_words\")\n",
    "    input_tags  = layers.Input(shape=(X_train_tags.shape[1],), name=\"input_tags\")\n",
    "\n",
    "    # Embedding Layers\n",
    "    # Transforms integer IDs into dense vectors\n",
    "    embed_words = layers.Embedding(input_dim=num_words, output_dim=word_embed_dim, name=\"embed_words\")(input_words)\n",
    "    embed_tags  = layers.Embedding(input_dim=num_tags, output_dim=pos_embed_dim, name=\"embed_tags\")(input_tags)\n",
    "\n",
    "    # Flattening\n",
    "    # Converts (batch, seq_len, emb_dim) to (batch, seq_len * emb_dim)\n",
    "    flat_words = layers.Flatten(name=\"flatten_words\")(embed_words)\n",
    "    flat_tags  = layers.Flatten(name=\"flatten_tags\")(embed_tags)\n",
    "\n",
    "    # Concatenation\n",
    "    # Merges word and tag features into a single vector\n",
    "    merged = layers.Concatenate(name=\"concat_features\")([flat_words, flat_tags])\n",
    "\n",
    "    # Shared Hidden Layer\n",
    "    # Learns representation useful for both tasks\n",
    "    hidden = layers.Dense(hidden_units, activation='relu', name=\"hidden_shared\")(merged)\n",
    "    \n",
    "    # Dropout for regularization\n",
    "    if dropout_rate > 0:\n",
    "        hidden = layers.Dropout(dropout_rate, name=\"dropout\")(hidden)\n",
    "\n",
    "    # Output Layers (Two Heads)\n",
    "    # 1. Predicts the transition action (SHIFT, REDUCE, LEFT-ARC, RIGHT-ARC)\n",
    "    output_action = layers.Dense(num_actions, activation='softmax', name=\"action_output\")(hidden)\n",
    "    # 2. Predicts the dependency label (nsubj, det, root, etc.)\n",
    "    output_label = layers.Dense(num_deprels, activation='softmax', name=\"label_output\")(hidden)\n",
    "\n",
    "    # Create the Model\n",
    "    model = models.Model(\n",
    "        inputs=[input_words, input_tags], \n",
    "        outputs=[output_action, output_label], \n",
    "        name=model_name\n",
    "    )\n",
    "\n",
    "    # Print Model Summary (Architecture and Parameters)\n",
    "    model.summary()\n",
    "\n",
    "    # --- 2. Compilation ---\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss={\n",
    "            \"action_output\": \"sparse_categorical_crossentropy\",\n",
    "            \"label_output\": \"sparse_categorical_crossentropy\"\n",
    "        },\n",
    "        metrics={\n",
    "            \"action_output\": [\"accuracy\"],\n",
    "            \"label_output\": [\"accuracy\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # --- 3. Callbacks ---\n",
    "    # Early Stopping configuration as requested:\n",
    "    # Monitor: 'val_action_output_accuracy' (Accuracy of the action prediction on validation set)\n",
    "    # Mode: 'max' (because we want accuracy to increase)\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_action_output_accuracy', \n",
    "        mode='max',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # --- 4. Training ---\n",
    "    print(\"\\nStarting Training...\")\n",
    "    history = model.fit(\n",
    "        x=[X_train_words, X_train_tags],\n",
    "        y=[y_train_act, y_train_dep],\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=([X_val_words, X_val_tags], [y_val_act, y_val_dep]),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1 # Ensures the epoch logs (Epoch 1/10...) are printed\n",
    "    )\n",
    "    \n",
    "    print(f\"--- Training Finished for {model_name} ---\")\n",
    "    return model, history\n",
    "\n",
    "# --- HYPERPARAMETER GRID DEFINITION ---\n",
    "# Expanded grid to test various configurations\n",
    "hyperparameter_grid = [\n",
    "    {\n",
    "        \"word_embed_dim\": 32, \"pos_embed_dim\": 10, \"hidden_units\": 100, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 32, \"dropout_rate\": 0.2,\n",
    "        \"model_name\": \"Base_Model\"\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 64, \"pos_embed_dim\": 20, \"hidden_units\": 200, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 64, \"dropout_rate\": 0.3,\n",
    "        \"model_name\": \"Large_Embeddings_HigherDrop\"\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 32, \"pos_embed_dim\": 10, \"hidden_units\": 100, \n",
    "        \"learning_rate\": 0.0005, \"batch_size\": 32, \"dropout_rate\": 0.2,\n",
    "        \"model_name\": \"Base_SlowLR\" # Slower learning rate for stability\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 16, \"pos_embed_dim\": 5, \"hidden_units\": 50, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 128, \"dropout_rate\": 0.1,\n",
    "        \"model_name\": \"Small_Fast_Model\" # Smaller model, larger batch size\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 64, \"pos_embed_dim\": 10, \"hidden_units\": 150, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 32, \"dropout_rate\": 0.4,\n",
    "        \"model_name\": \"High_Dropout_Regularization\" # Heavy regularization\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 32, \"pos_embed_dim\": 10, \"hidden_units\": 300, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 64, \"dropout_rate\": 0.2,\n",
    "        \"model_name\": \"Wide_Hidden_Layer\" # Large hidden layer capacity\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- EXECUTION LOOP ---\n",
    "\n",
    "all_histories = {}\n",
    "best_val_accuracy = 0.0\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "\n",
    "print(f\"Starting Hyperparameter Search over {len(hyperparameter_grid)} models...\")\n",
    "\n",
    "for params in hyperparameter_grid:\n",
    "    \n",
    "    # Call the function with the current parameters\n",
    "    # Assumes X_train_words, NUM_WORDS, etc., are already defined in the notebook context\n",
    "    model, history = build_and_train_parser(\n",
    "        X_train_words, X_train_tags, y_train_act, y_train_dep,\n",
    "        X_val_words, X_val_tags, y_val_act, y_val_dep,\n",
    "        NUM_WORDS, NUM_TAGS, NUM_ACTIONS, NUM_DEPRELS,\n",
    "        word_embed_dim=params[\"word_embed_dim\"],\n",
    "        pos_embed_dim=params[\"pos_embed_dim\"],\n",
    "        hidden_units=params[\"hidden_units\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        dropout_rate=params[\"dropout_rate\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        epochs=15, # Set max epochs (EarlyStopping will likely cut this shorter)\n",
    "        model_name=params[\"model_name\"]\n",
    "    )\n",
    "    \n",
    "    # Store history\n",
    "    all_histories[params[\"model_name\"]] = history.history\n",
    "    \n",
    "    # Evaluate performance\n",
    "    # We check the best validation accuracy for the action output achieved during training\n",
    "    best_epoch_acc = max(history.history['val_action_output_accuracy'])\n",
    "    print(f\"Result {params['model_name']}: Best Validation Action Accuracy = {best_epoch_acc:.4f}\")\n",
    "    \n",
    "    # Track the global best model\n",
    "    if best_epoch_acc > best_val_accuracy:\n",
    "        print(f\" >> New Best Model Found! (Previous best: {best_val_accuracy:.4f})\")\n",
    "        best_val_accuracy = best_epoch_acc\n",
    "        best_model = model\n",
    "        best_model_name = params[\"model_name\"]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SEARCH COMPLETE\")\n",
    "print(f\"Best Model: '{best_model_name}' with Action Accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# --- SAVE BEST MODEL ---\n",
    "if best_model:\n",
    "    save_filename = f\"{best_model_name}_best.keras\"\n",
    "    print(f\"Saving best model to: {save_filename}\")\n",
    "    best_model.save(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdcef3-8e0c-4b80-8ccd-95dbd0c819cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
