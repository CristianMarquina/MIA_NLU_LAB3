{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2850f8b6-4428-4c96-a969-725832d54cd6",
   "metadata": {},
   "source": [
    "## Stage 2: Data Preparation Pipeline & Feature Extraction\n",
    "\n",
    "Milestone: Implementation of the oracle, feature extraction, and obtaining training samples for a Keras model.\n",
    "\n",
    "In this section, we execute the complete data processing pipeline to transform the raw CoNLL-U training data into numerical vectors that can be fed into the Neural Network. This process involves four main steps:\n",
    "\n",
    "\n",
    "Data Loading & Filtering: We load the training dataset (en_partut-ud-train.conllu) and filter out non-projective trees, as the Arc-Eager algorithm is restricted to projective dependency structures.\n",
    "\n",
    "Oracle Execution (Obtaining Samples): We run the Oracle on every valid sentence. The Oracle simulates the parsing process using the \"gold standard\" tree to generate the correct sequence of States (Input) and Transitions (Output/Target).\n",
    "\n",
    "\n",
    "Feature Extraction: We convert the complex State objects into fixed-length lists of features using the state_to_feats function. This extracts the specific words and UPOS tags from the top of the Stack and the Buffer.\n",
    "\n",
    "\n",
    "Numerical Conversion (Vectorization): Neural networks require numerical input. We build vocabularies (dictionaries mapping strings to unique Integer IDs) for words, tags, actions, and dependency labels. Finally, we convert all text features into Numpy arrays (X_train, y_act, y_dep) ready for Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119375a6-1679-4692-a15b-b51a760802b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Data Loading ---\n",
      " Loaded 1748 valid projective sentences for training.\n",
      "\n",
      "--- STEP 2: Generating Samples with the Oracle ---\n",
      "Total samples (game states) generated: 81182\n",
      "Example of Raw Sample (Index 0):\n",
      "   State: Stack (size=1): (0, ROOT, ROOT_UPOS)\n",
      "Buffer (size=13): (1, Distribution, NOUN) | (2, of, ADP) | (3, this, DET) | (4, license, NOUN) | (5, does, AUX) | (6, not, PART) | (7, create, VERB) | (8, an, DET) | (9, attorney, NOUN) | (10, -, PUNCT) | (11, client, NOUN) | (12, relationship, NOUN) | (13, ., PUNCT)\n",
      "Arcs (size=0): set()\n",
      "\n",
      "   Correct Action: SHIFT\n",
      "\n",
      "--- STEP 3: Feature Extraction (Translation to Text) ---\n",
      " Example of Input (X_raw[0]): ['<PAD>', 'ROOT', 'Distribution', 'of', '<PAD>', 'ROOT_UPOS', 'NOUN', 'ADP']\n",
      "   (This is what the network 'sees': words and tags)\n",
      "Example of Output (Y_raw[0]): ('SHIFT', None)\n",
      "   (This is what the network must predict: Action and Label)\n",
      "\n",
      "--- STEP 4: Numerical Conversion (For Keras) ---\n",
      "Vocabulary Sizes:\n",
      "   Unique words: 6872\n",
      "   Unique UPOS tags: 20\n",
      "   Possible actions: 4 {'SHIFT': 0, 'LEFT-ARC': 1, 'RIGHT-ARC': 2, 'REDUCE': 3}\n",
      "   Dependency relations: 44\n",
      "\n",
      "DATA\n",
      "Final numerical example (X_train[0]): [0 2 3 4 0 2 3 4]\n",
      "   (Notice how words are now IDs)\n",
      "Target Action (y_act[0]): 0 -> Corresponds to 'SHIFT'\n",
      "Target Action (y_act[0]): 0 -> Corresponds to 'SHIFT'\n",
      "Data saved to 'training_data.npz' and 'vocabs.pkl'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from conllu_reader import ConlluReader\n",
    "from algorithm import ArcEager\n",
    "import pickle\n",
    "\n",
    "# --- 1. LOAD DATA (Use the TRAIN file, not test) ---\n",
    "print(\"--- STEP 1: Data Loading ---\")\n",
    "reader = ConlluReader()\n",
    "# Ensure the filename matches your specific training file path\n",
    "train_sentences = reader.read_conllu_file(\"en_partut-ud-train_clean.conllu\") \n",
    "\n",
    "# Filter out non-projective trees as Arc-Eager cannot handle them [cite: 1100]\n",
    "train_sentences = reader.remove_non_projective_trees(train_sentences)\n",
    "print(f\" Loaded {len(train_sentences)} valid projective sentences for training.\\n\")\n",
    "\n",
    "# --- 2. OBTAIN RAW SAMPLES (Oracle Execution) ---\n",
    "print(\"--- STEP 2: Generating Samples with the Oracle ---\")\n",
    "arc_eager = ArcEager()\n",
    "raw_samples = []\n",
    "\n",
    "for sent in train_sentences:\n",
    "    try:\n",
    "        # The oracle returns a list of Sample objects (State + Transition) for this sentence\n",
    "        samples = arc_eager.oracle(sent)\n",
    "        raw_samples.extend(samples)\n",
    "    except AssertionError:\n",
    "        # If the oracle fails to reconstruct the exact gold tree, skip the sentence\n",
    "        continue\n",
    "\n",
    "print(f\"Total samples (game states) generated: {len(raw_samples)}\")\n",
    "\n",
    "# VISUALIZATION: Let's see what a raw sample looks like\n",
    "if raw_samples:\n",
    "    print(f\"Example of Raw Sample (Index 0):\")\n",
    "    print(f\"   State: {raw_samples[0].state}\")\n",
    "    print(f\"   Correct Action: {raw_samples[0].transition}\\n\")\n",
    "\n",
    "# --- 3. FEATURE EXTRACTION (From State to List of Strings) ---\n",
    "# We need to extract features from the stack and buffer [cite: 934, 1080]\n",
    "print(\"--- STEP 3: Feature Extraction (Translation to Text) ---\")\n",
    "X_raw = [] # Stores lists of words/tags (Input features)\n",
    "Y_raw = [] # Stores actions and dependencies (Outputs)\n",
    "\n",
    "for sample in raw_samples:\n",
    "    # Extract features (words and UPOS tags) using the implemented function\n",
    "    # nbuffer_feats=2 and nstack_feats=2 is the suggested configuration [cite: 1091]\n",
    "    features = sample.state_to_feats(nbuffer_feats=2, nstack_feats=2)\n",
    "    X_raw.append(features)\n",
    "    \n",
    "    # Save the action (transition) and the dependency label\n",
    "    action_name = sample.transition.action\n",
    "    dep_label = sample.transition.dependency\n",
    "    Y_raw.append((action_name, dep_label))\n",
    "\n",
    "# VISUALIZATION: What do the lists contain now?\n",
    "print(f\" Example of Input (X_raw[0]): {X_raw[0]}\")\n",
    "print(f\"   (This is what the network 'sees': words and tags)\")\n",
    "print(f\"Example of Output (Y_raw[0]): {Y_raw[0]}\")\n",
    "print(f\"   (This is what the network must predict: Action and Label)\\n\")\n",
    "\n",
    "# --- 4. PREPARATION FOR KERAS (Vocabularies and Numerical Conversion) ---\n",
    "# Neural networks require numerical input [cite: 733]\n",
    "print(\"--- STEP 4: Numerical Conversion (For Keras) ---\")\n",
    "\n",
    "# 4.1 Create Dictionaries (Text -> Number Maps)\n",
    "words_vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "upos_vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "actions_vocab = {}  # E.g., 'SHIFT': 0, 'LEFT-ARC': 1...\n",
    "deprels_vocab = {None: 0} # E.g., 'nsubj': 1, 'det': 2...\n",
    "\n",
    "# Fill vocabularies by iterating through all collected data\n",
    "for features in X_raw:\n",
    "    # Assuming features structure: [W_s2, W_s1, W_b1, W_b2, P_s2, P_s1, P_b1, P_b2]\n",
    "    # The first half are words, the second half are UPOS tags\n",
    "    num_words = len(features) // 2 \n",
    "    \n",
    "    words = features[:num_words]\n",
    "    upos = features[num_words:]\n",
    "    \n",
    "    for w in words:\n",
    "        if w not in words_vocab:\n",
    "            words_vocab[w] = len(words_vocab)\n",
    "    for u in upos:\n",
    "        if u not in upos_vocab:\n",
    "            upos_vocab[u] = len(upos_vocab)\n",
    "\n",
    "for act, dep in Y_raw:\n",
    "    if act not in actions_vocab:\n",
    "        actions_vocab[act] = len(actions_vocab)\n",
    "    if dep not in deprels_vocab:\n",
    "        deprels_vocab[dep] = len(deprels_vocab)\n",
    "\n",
    "print(f\"Vocabulary Sizes:\")\n",
    "print(f\"   Unique words: {len(words_vocab)}\")\n",
    "print(f\"   Unique UPOS tags: {len(upos_vocab)}\")\n",
    "print(f\"   Possible actions: {len(actions_vocab)} {actions_vocab}\")\n",
    "print(f\"   Dependency relations: {len(deprels_vocab)}\\n\")\n",
    "\n",
    "# 4.2 Convert everything to Numbers (Matrices for Keras)\n",
    "# X_train will have shape (Num_Samples, Num_Features)\n",
    "X_train_numerical = []\n",
    "Y_train_actions = []\n",
    "Y_train_deprels = []\n",
    "\n",
    "for i in range(len(X_raw)):\n",
    "    # Convert INPUT (Features)\n",
    "    features = X_raw[i]\n",
    "    num_vec = []\n",
    "    \n",
    "    # Convert words to IDs\n",
    "    num_words = len(features) // 2\n",
    "    for w in features[:num_words]:\n",
    "        num_vec.append(words_vocab.get(w, words_vocab['<UNK>']))\n",
    "    # Convert UPOS tags to IDs\n",
    "    for u in features[num_words:]:\n",
    "        num_vec.append(upos_vocab.get(u, upos_vocab['<UNK>']))\n",
    "    \n",
    "    X_train_numerical.append(num_vec)\n",
    "    \n",
    "    # Convert OUTPUT (Targets)\n",
    "    act, dep = Y_raw[i]\n",
    "    Y_train_actions.append(actions_vocab[act])\n",
    "    # Use 0 if the dependency is None (e.g., for SHIFT or REDUCE)\n",
    "    Y_train_deprels.append(deprels_vocab.get(dep, 0)) \n",
    "\n",
    "# Convert to Numpy arrays (The actual input format Keras expects)\n",
    "X_train = np.array(X_train_numerical)\n",
    "y_act = np.array(Y_train_actions)\n",
    "y_dep = np.array(Y_train_deprels)\n",
    "\n",
    "print(\"DATA\")\n",
    "print(f\"Final numerical example (X_train[0]): {X_train[0]}\")\n",
    "print(f\"   (Notice how words are now IDs)\")\n",
    "# Find the action name corresponding to the ID for display purposes\n",
    "act_name = list(actions_vocab.keys())[list(actions_vocab.values()).index(y_act[0])]\n",
    "print(f\"Target Action (y_act[0]): {y_act[0]} -> Corresponds to '{act_name}'\")\n",
    "\n",
    "print(f\"Target Action (y_act[0]): {y_act[0]} -> Corresponds to '{act_name}'\")\n",
    "np.savez(\"training_data.npz\", X=X_train, y_act=y_act, y_dep=y_dep)\n",
    "with open(\"vocabs.pkl\", \"wb\") as f:\n",
    "    pickle.dump((words_vocab, upos_vocab, actions_vocab, deprels_vocab), f)\n",
    "print(\"Data saved to 'training_data.npz' and 'vocabs.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2865f5-40b2-46d9-bc29-f8b9e505bb47",
   "metadata": {},
   "source": [
    "## Verificaion del oracle que esta haciendo bien su trabajo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6d5a0e-388c-4f55-8cc1-a5cbf3c55d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VERIFICACIÓN: Oracle vs Gold Standard + Input Red Neuronal ---\n",
      "Oración: ['ROOT', 'Distribution', 'of', 'this', 'license', 'does', 'not', 'create', 'an', 'attorney', '-', 'client', 'relationship', '.']\n",
      "Paso | Pila (Stack)              | Búfer (Buffer)            | Acción Real     | Input para Red Neuronal (Features)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "0    | ['ROOT']                  | ['Distribution', 'of']... | SHIFT           | ['<PAD>', 'ROOT', 'Distribution', 'of', '<PAD>', 'ROOT_UPOS', 'NOUN', 'ADP']\n",
      "1    | ['ROOT', 'Distribution']  | ['of', 'this']...         | SHIFT           | ['ROOT', 'Distribution', 'of', 'this', 'ROOT_UPOS', 'NOUN', 'ADP', 'DET']\n",
      "2    | T', 'Distribution', 'of'] | ['this', 'license']...    | SHIFT           | ['Distribution', 'of', 'this', 'license', 'NOUN', 'ADP', 'DET', 'NOUN']\n",
      "3    | tribution', 'of', 'this'] | ['license', 'does']...    | LEFT-ARC-det    | ['of', 'this', 'license', 'does', 'ADP', 'DET', 'NOUN', 'AUX']\n",
      "4    | T', 'Distribution', 'of'] | ['license', 'does']...    | LEFT-ARC-case   | ['Distribution', 'of', 'license', 'does', 'NOUN', 'ADP', 'NOUN', 'AUX']\n",
      "5    | ['ROOT', 'Distribution']  | ['license', 'does']...    | RIGHT-ARC-nmod  | ['ROOT', 'Distribution', 'license', 'does', 'ROOT_UPOS', 'NOUN', 'NOUN', 'AUX']\n",
      "6    | Distribution', 'license'] | ['does', 'not']...        | REDUCE          | ['Distribution', 'license', 'does', 'not', 'NOUN', 'NOUN', 'AUX', 'PART']\n",
      "7    | ['ROOT', 'Distribution']  | ['does', 'not']...        | SHIFT           | ['ROOT', 'Distribution', 'does', 'not', 'ROOT_UPOS', 'NOUN', 'AUX', 'PART']\n",
      "8    | , 'Distribution', 'does'] | ['not', 'create']...      | SHIFT           | ['Distribution', 'does', 'not', 'create', 'NOUN', 'AUX', 'PART', 'VERB']\n",
      "9    | ribution', 'does', 'not'] | ['create', 'an']...       | LEFT-ARC-advmod | ['does', 'not', 'create', 'an', 'AUX', 'PART', 'VERB', 'DET']\n",
      "10   | , 'Distribution', 'does'] | ['create', 'an']...       | LEFT-ARC-aux    | ['Distribution', 'does', 'create', 'an', 'NOUN', 'AUX', 'VERB', 'DET']\n",
      "11   | ['ROOT', 'Distribution']  | ['create', 'an']...       | LEFT-ARC-nsubj  | ['ROOT', 'Distribution', 'create', 'an', 'ROOT_UPOS', 'NOUN', 'VERB', 'DET']\n",
      "12   | ['ROOT']                  | ['create', 'an']...       | RIGHT-ARC-root  | ['<PAD>', 'ROOT', 'create', 'an', '<PAD>', 'ROOT_UPOS', 'VERB', 'DET']\n",
      "13   | ['ROOT', 'create']        | ['an', 'attorney']...     | SHIFT           | ['ROOT', 'create', 'an', 'attorney', 'ROOT_UPOS', 'VERB', 'DET', 'NOUN']\n",
      "14   | ['ROOT', 'create', 'an']  | ['attorney', '-']...      | SHIFT           | ['create', 'an', 'attorney', '-', 'VERB', 'DET', 'NOUN', 'PUNCT']\n",
      "15   | reate', 'an', 'attorney'] | ['-', 'client']...        | RIGHT-ARC-punct | ['an', 'attorney', '-', 'client', 'DET', 'NOUN', 'PUNCT', 'NOUN']\n",
      "16   | ', 'an', 'attorney', '-'] | ['client', 'relationship']... | REDUCE          | ['attorney', '-', 'client', 'relationship', 'NOUN', 'PUNCT', 'NOUN', 'NOUN']\n",
      "17   | reate', 'an', 'attorney'] | ['client', 'relationship']... | RIGHT-ARC-compound | ['an', 'attorney', 'client', 'relationship', 'DET', 'NOUN', 'NOUN', 'NOUN']\n",
      "18   | n', 'attorney', 'client'] | ['relationship', '.']...  | REDUCE          | ['attorney', 'client', 'relationship', '.', 'NOUN', 'NOUN', 'NOUN', 'PUNCT']\n",
      "19   | reate', 'an', 'attorney'] | ['relationship', '.']...  | LEFT-ARC-nmod   | ['an', 'attorney', 'relationship', '.', 'DET', 'NOUN', 'NOUN', 'PUNCT']\n",
      "20   | ['ROOT', 'create', 'an']  | ['relationship', '.']...  | LEFT-ARC-det    | ['create', 'an', 'relationship', '.', 'VERB', 'DET', 'NOUN', 'PUNCT']\n",
      "21   | ['ROOT', 'create']        | ['relationship', '.']...  | RIGHT-ARC-obj   | ['ROOT', 'create', 'relationship', '.', 'ROOT_UPOS', 'VERB', 'NOUN', 'PUNCT']\n",
      "22   | 'create', 'relationship'] | ['.']...                  | REDUCE          | ['create', 'relationship', '.', '<PAD>', 'VERB', 'NOUN', 'PUNCT', '<PAD>']\n",
      "23   | ['ROOT', 'create']        | ['.']...                  | RIGHT-ARC-punct | ['ROOT', 'create', '.', '<PAD>', 'ROOT_UPOS', 'VERB', 'PUNCT', '<PAD>']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Comparación de Arcos (Dependencias):\n",
      "Total arcos Gold (Reales): 13\n",
      "Total arcos Generados: 13\n",
      "\n",
      "✅ ¡ÉXITO! El oráculo reconstruyó el árbol perfectamente.\n",
      "Los inputs mostrados arriba son correctos para entrenar la red.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- VERIFICACIÓN: Oracle vs Gold Standard + Input Red Neuronal ---\")\n",
    "\n",
    "# 1. Seleccionamos una oración de ejemplo\n",
    "example_sent = train_sentences[0]\n",
    "print(f\"Oración: {[t.form for t in example_sent]}\")\n",
    "\n",
    "# 2. Obtenemos las transiciones del oráculo\n",
    "try:\n",
    "    oracle_samples = arc_eager.oracle(example_sent)\n",
    "except AssertionError as e:\n",
    "    print(f\"El oráculo falló en esta oración: {e}\")\n",
    "else:\n",
    "    # 3. Simulamos el parseo paso a paso\n",
    "    # CORRECCIÓN: Usamos el método correcto 'create_initial_state'\n",
    "    config = arc_eager.create_initial_state(example_sent)\n",
    "    \n",
    "    print(f\"{'Paso':<4} | {'Pila (Stack)':<25} | {'Búfer (Buffer)':<25} | {'Acción Real':<15} | {'Input para Red Neuronal (Features)'}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    for i, sample in enumerate(oracle_samples):\n",
    "        # Preparamos visualización del estado\n",
    "        stack_str = str([t.form for t in config.S])\n",
    "        buffer_str = str([t.form for t in config.B[:2]]) + \"...\" # Solo los primeros 2 del buffer\n",
    "        \n",
    "        # Acción tomada\n",
    "        action_str = str(sample.transition)\n",
    "        \n",
    "        # --- ESTO ES EL INPUT DE LA RED NEURONAL ---\n",
    "        # Usamos el método state_to_feats que ya tiene tu clase Sample.\n",
    "        # Esto extrae las palabras y tags de la Pila y el Búfer.\n",
    "        nn_input = sample.state_to_feats(nbuffer_feats=2, nstack_feats=2)\n",
    "        \n",
    "        # Imprimimos la fila\n",
    "        # stack_str[-25:] corta el string si es muy largo para que quepa\n",
    "        print(f\"{i:<4} | {stack_str[-25:]:<25} | {buffer_str:<25} | {action_str:<15} | {nn_input}\")\n",
    "\n",
    "        # Avanzamos la simulación aplicando la transición\n",
    "        arc_eager.apply_transition(config, sample.transition)-\n",
    "\n",
    "    # 4. Comparación Final\n",
    "    print(\"-\" * 120)\n",
    "    print(\"Comparación de Arcos (Dependencias):\")\n",
    "    \n",
    "    # Usamos el método gold_arcs que ya tienes en algorithm.py\n",
    "    gold_arcs = arc_eager.gold_arcs(example_sent)\n",
    "    generated_arcs = config.A # Los arcos que generó nuestra simulación\n",
    "    \n",
    "    print(f\"Total arcos Gold (Reales): {len(gold_arcs)}\")\n",
    "    print(f\"Total arcos Generados: {len(generated_arcs)}\")\n",
    "    \n",
    "    if gold_arcs == generated_arcs:\n",
    "        print(\"\\n✅ ¡ÉXITO! El oráculo reconstruyó el árbol perfectamente.\")\n",
    "        print(\"Los inputs mostrados arriba son correctos para entrenar la red.\")\n",
    "    else:\n",
    "        print(\"\\n❌ ERROR: Los árboles no coinciden.\")\n",
    "        print(\"Arcos faltantes:\", gold_arcs - generated_arcs)\n",
    "        print(\"Arcos sobrantes:\", generated_arcs - gold_arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f58fe69-f6c9-4332-9264-1929de6953c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Loading Training Data and Vocabularies ---\n",
      "Training samples: 73063\n",
      "Validation samples: 8119\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import pickle\n",
    "\n",
    "# --- 1. LOAD PREPARED DATA ---\n",
    "print(\"--- STEP 1: Loading Training Data and Vocabularies ---\")\n",
    "\n",
    "try:\n",
    "    data = np.load(\"training_data.npz\")\n",
    "    X_train_full = data['X']      # Shape: (Num_Samples, 8) -> 4 words + 4 tags\n",
    "    y_train_act_full = data['y_act']   # Shape: (Num_Samples,) -> Action IDs\n",
    "    y_train_dep_full = data['y_dep']   # Shape: (Num_Samples,) -> Dependency IDs\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'training_data.npz' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Load vocabularies\n",
    "try:\n",
    "    with open(\"vocabs.pkl\", \"rb\") as f:\n",
    "        words_vocab, upos_vocab, actions_vocab, deprels_vocab = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'vocabs.pkl' not found.\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Splitting ---\n",
    "split_idx = int(len(X_train_full) * 0.9)\n",
    "\n",
    "# Inputs\n",
    "X_train, X_val = X_train_full[:split_idx], X_train_full[split_idx:]\n",
    "\n",
    "# Outputs (We need TWO sets of targets now)\n",
    "y_train_act, y_val_act = y_train_act_full[:split_idx], y_train_act_full[split_idx:]\n",
    "y_train_dep, y_val_dep = y_train_dep_full[:split_idx], y_train_dep_full[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "\n",
    "# --- 2. SEPARATE INPUTS (Words vs Tags) ---\n",
    "# X contains [Word_S2, Word_S1, Word_B1, Word_B2, Tag_S2, Tag_S1, Tag_B1, Tag_B2]\n",
    "num_features_total = X_train.shape[1]\n",
    "num_word_feats = num_features_total // 2 \n",
    "\n",
    "X_train_words = X_train[:, :num_word_feats]\n",
    "X_train_tags  = X_train[:, num_word_feats:]\n",
    "\n",
    "X_val_words = X_val[:, :num_word_feats]\n",
    "X_val_tags  = X_val[:, num_word_feats:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59a10abc-f193-4dca-9a92-58fcf048c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1 (Actions): 4 classes\n",
      "Output 2 (Labels): 44 classes\n",
      "--- STEP 2: Building Multi-Output Neural Network ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:19:37.202687: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ArcEager_MultiOutput_Parser\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ArcEager_MultiOutput_Parser\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,936</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,900</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_shared[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,444</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │    \u001b[38;5;34m219,936\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m210\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m16,900\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_shared[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m404\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m4,444\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">241,894</span> (944.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m241,894\u001b[0m (944.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">241,894</span> (944.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m241,894\u001b[0m (944.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3. DEFINE HYPERPARAMETERS ---\n",
    "WORD_EMBED_DIM = 32\n",
    "POS_EMBED_DIM = 10\n",
    "HIDDEN_UNITS = 100\n",
    "\n",
    "NUM_WORDS = len(words_vocab) + 1\n",
    "NUM_TAGS = len(upos_vocab) + 1\n",
    "NUM_ACTIONS = len(actions_vocab)  # Output 1 size (e.g., 4: SHIFT, REDUCE, LA, RA)\n",
    "NUM_DEPRELS = len(deprels_vocab)  # Output 2 size (e.g., 44 dependency labels)\n",
    "\n",
    "print(f\"Output 1 (Actions): {NUM_ACTIONS} classes\")\n",
    "print(f\"Output 2 (Labels): {NUM_DEPRELS} classes\")\n",
    "\n",
    "\n",
    "# --- 4. BUILD THE MODEL (Multi-Output) ---\n",
    "print(\"--- STEP 2: Building Multi-Output Neural Network ---\")\n",
    "\n",
    "# A. Input Layers\n",
    "input_words = layers.Input(shape=(num_word_feats,), name=\"input_words\")\n",
    "input_tags  = layers.Input(shape=(num_word_feats,), name=\"input_tags\")\n",
    "\n",
    "# B. Embedding Layers\n",
    "embed_words = layers.Embedding(input_dim=NUM_WORDS, output_dim=WORD_EMBED_DIM, name=\"embed_words\")(input_words)\n",
    "embed_tags  = layers.Embedding(input_dim=NUM_TAGS, output_dim=POS_EMBED_DIM, name=\"embed_tags\")(input_tags)\n",
    "\n",
    "# C. Flatten & Concatenate\n",
    "flat_words = layers.Flatten()(embed_words)\n",
    "flat_tags  = layers.Flatten()(embed_tags)\n",
    "merged = layers.Concatenate(name=\"concat_features\")([flat_words, flat_tags])\n",
    "\n",
    "# D. Shared Hidden Layers\n",
    "# This layer learns features relevant for BOTH tasks (action and label prediction)\n",
    "hidden = layers.Dense(HIDDEN_UNITS, activation='relu', name=\"hidden_shared\")(merged)\n",
    "hidden = layers.Dropout(0.2)(hidden)\n",
    "\n",
    "# E. Output Layers (The Two Heads)\n",
    "# Head 1: Predicts the transition action (SHIFT, REDUCE, etc.)\n",
    "output_action = layers.Dense(NUM_ACTIONS, activation='softmax', name=\"action_output\")(hidden)\n",
    "\n",
    "# Head 2: Predicts the dependency label (nsubj, det, etc.)\n",
    "output_label = layers.Dense(NUM_DEPRELS, activation='softmax', name=\"label_output\")(hidden)\n",
    "\n",
    "# Create Model with 2 inputs and 2 outputs\n",
    "model = models.Model(\n",
    "    inputs=[input_words, input_tags], \n",
    "    outputs=[output_action, output_label], \n",
    "    name=\"ArcEager_MultiOutput_Parser\"\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85edb681-5587-48ae-8683-287c03f37b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 3: Training the Model ---\n",
      "Epoch 1/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.8223 - action_output_loss: 0.4640 - label_output_accuracy: 0.7633 - label_output_loss: 0.8593 - loss: 1.3231 - val_action_output_accuracy: 0.8671 - val_action_output_loss: 0.3514 - val_label_output_accuracy: 0.8316 - val_label_output_loss: 0.4959 - val_loss: 0.8480\n",
      "Epoch 2/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.8958 - action_output_loss: 0.2802 - label_output_accuracy: 0.8608 - label_output_loss: 0.4267 - loss: 0.7069 - val_action_output_accuracy: 0.8632 - val_action_output_loss: 0.3559 - val_label_output_accuracy: 0.8436 - val_label_output_loss: 0.4461 - val_loss: 0.8027\n",
      "Epoch 3/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9245 - action_output_loss: 0.2079 - label_output_accuracy: 0.8957 - label_output_loss: 0.3193 - loss: 0.5273 - val_action_output_accuracy: 0.8632 - val_action_output_loss: 0.3758 - val_label_output_accuracy: 0.8467 - val_label_output_loss: 0.4411 - val_loss: 0.8176\n",
      "Epoch 4/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9407 - action_output_loss: 0.1635 - label_output_accuracy: 0.9198 - label_output_loss: 0.2448 - loss: 0.4084 - val_action_output_accuracy: 0.8561 - val_action_output_loss: 0.4084 - val_label_output_accuracy: 0.8443 - val_label_output_loss: 0.4782 - val_loss: 0.8875\n",
      "Epoch 5/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9515 - action_output_loss: 0.1355 - label_output_accuracy: 0.9366 - label_output_loss: 0.2006 - loss: 0.3362 - val_action_output_accuracy: 0.8550 - val_action_output_loss: 0.4443 - val_label_output_accuracy: 0.8411 - val_label_output_loss: 0.5076 - val_loss: 0.9527\n",
      "Epoch 6/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9590 - action_output_loss: 0.1144 - label_output_accuracy: 0.9487 - label_output_loss: 0.1630 - loss: 0.2773 - val_action_output_accuracy: 0.8527 - val_action_output_loss: 0.4855 - val_label_output_accuracy: 0.8415 - val_label_output_loss: 0.5542 - val_loss: 1.0407\n",
      "Epoch 7/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9651 - action_output_loss: 0.0982 - label_output_accuracy: 0.9569 - label_output_loss: 0.1369 - loss: 0.2351 - val_action_output_accuracy: 0.8517 - val_action_output_loss: 0.5290 - val_label_output_accuracy: 0.8358 - val_label_output_loss: 0.5963 - val_loss: 1.1262\n",
      "Epoch 8/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9688 - action_output_loss: 0.0867 - label_output_accuracy: 0.9637 - label_output_loss: 0.1151 - loss: 0.2018 - val_action_output_accuracy: 0.8521 - val_action_output_loss: 0.5578 - val_label_output_accuracy: 0.8364 - val_label_output_loss: 0.6349 - val_loss: 1.1936\n",
      "Epoch 9/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - action_output_accuracy: 0.9726 - action_output_loss: 0.0770 - label_output_accuracy: 0.9680 - label_output_loss: 0.1004 - loss: 0.1772 - val_action_output_accuracy: 0.8506 - val_action_output_loss: 0.5983 - val_label_output_accuracy: 0.8385 - val_label_output_loss: 0.6825 - val_loss: 1.2818\n",
      "Epoch 10/10\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - action_output_accuracy: 0.9758 - action_output_loss: 0.0674 - label_output_accuracy: 0.9716 - label_output_loss: 0.0875 - loss: 0.1549 - val_action_output_accuracy: 0.8487 - val_action_output_loss: 0.6373 - val_label_output_accuracy: 0.8342 - val_label_output_loss: 0.7362 - val_loss: 1.3747\n",
      "--- STEP 4: Saving Model ---\n",
      "Model saved to 'parser_model_multi.keras'\n"
     ]
    }
   ],
   "source": [
    "# --- 5. COMPILE AND TRAIN ---\n",
    "print(\"--- STEP 3: Training the Model ---\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    # We define a loss function for EACH output layer (by name or order)\n",
    "    loss={\n",
    "        \"action_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"label_output\": \"sparse_categorical_crossentropy\"\n",
    "    },\n",
    "    # We calculate accuracy for each output separately\n",
    "    metrics={\n",
    "        \"action_output\": [\"accuracy\"],\n",
    "        \"label_output\": [\"accuracy\"]\n",
    "    },\n",
    "    # Optional: Weigh the losses. Maybe action is more critical than label?\n",
    "    # loss_weights={\"action_output\": 1.0, \"label_output\": 1.0} \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "# Note: 'y' is now a LIST of targets [actions, labels] corresponding to the outputs\n",
    "history = model.fit(\n",
    "    x=[X_train_words, X_train_tags],\n",
    "    y=[y_train_act, y_train_dep],  \n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_val_words, X_val_tags], [y_val_act, y_val_dep]),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- 6. SAVE THE MODEL ---\n",
    "print(\"--- STEP 4: Saving Model ---\")\n",
    "model.save(\"parser_model_multi.keras\")\n",
    "print(\"Model saved to 'parser_model_multi.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba5b103d-9c5b-47a3-8892-8306866d456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 23:19:03.379476: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-25 23:19:03.379799: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-25 23:19:03.420462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-11-25 23:19:04.427824: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-25 23:19:04.428201: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_and_train_parser(\n",
    "    # Input Data\n",
    "    X_train_words, X_train_tags, y_train_act, y_train_dep,\n",
    "    X_val_words, X_val_tags, y_val_act, y_val_dep,\n",
    "    # Fixed Dimensions (Vocabularies)\n",
    "    num_words, num_tags, num_actions, num_deprels,\n",
    "    # Hyperparameters (Variables)\n",
    "    word_embed_dim=32,\n",
    "    pos_embed_dim=10,\n",
    "    hidden_units=100,\n",
    "    learning_rate=0.001,\n",
    "    dropout_rate=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    model_name=\"Parser_Model\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds, compiles, and trains a multi-output neural network for dependency parsing.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING MODEL: {model_name}\")\n",
    "    print(f\"Params: WordEmb={word_embed_dim}, PosEmb={pos_embed_dim}, Hidden={hidden_units}, LR={learning_rate}, Drop={dropout_rate}, Batch={batch_size}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # --- 1. Architecture ---\n",
    "    \n",
    "    # Input Layers\n",
    "    # Shape is determined by the number of features selected (e.g., 2 stack + 2 buffer = 4)\n",
    "    input_words = layers.Input(shape=(X_train_words.shape[1],), name=\"input_words\")\n",
    "    input_tags  = layers.Input(shape=(X_train_tags.shape[1],), name=\"input_tags\")\n",
    "\n",
    "    # Embedding Layers\n",
    "    # Transforms integer IDs into dense vectors\n",
    "    embed_words = layers.Embedding(input_dim=num_words, output_dim=word_embed_dim, name=\"embed_words\")(input_words)\n",
    "    embed_tags  = layers.Embedding(input_dim=num_tags, output_dim=pos_embed_dim, name=\"embed_tags\")(input_tags)\n",
    "\n",
    "    # Flattening\n",
    "    # Converts (batch, seq_len, emb_dim) to (batch, seq_len * emb_dim)\n",
    "    flat_words = layers.Flatten(name=\"flatten_words\")(embed_words)\n",
    "    flat_tags  = layers.Flatten(name=\"flatten_tags\")(embed_tags)\n",
    "\n",
    "    # Concatenation\n",
    "    # Merges word and tag features into a single vector\n",
    "    merged = layers.Concatenate(name=\"concat_features\")([flat_words, flat_tags])\n",
    "\n",
    "    # Shared Hidden Layer\n",
    "    # Learns representation useful for both tasks\n",
    "    hidden = layers.Dense(hidden_units, activation='relu', name=\"hidden_shared\")(merged)\n",
    "    \n",
    "    # Dropout for regularization\n",
    "    if dropout_rate > 0:\n",
    "        hidden = layers.Dropout(dropout_rate, name=\"dropout\")(hidden)\n",
    "\n",
    "    # Output Layers (Two Heads)\n",
    "    # 1. Predicts the transition action (SHIFT, REDUCE, LEFT-ARC, RIGHT-ARC)\n",
    "    output_action = layers.Dense(num_actions, activation='softmax', name=\"action_output\")(hidden)\n",
    "    # 2. Predicts the dependency label (nsubj, det, root, etc.)\n",
    "    output_label = layers.Dense(num_deprels, activation='softmax', name=\"label_output\")(hidden)\n",
    "\n",
    "    # Create the Model\n",
    "    model = models.Model(\n",
    "        inputs=[input_words, input_tags], \n",
    "        outputs=[output_action, output_label], \n",
    "        name=model_name\n",
    "    )\n",
    "\n",
    "    # Print Model Summary (Architecture and Parameters)\n",
    "    model.summary()\n",
    "\n",
    "    # --- 2. Compilation ---\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss={\n",
    "            \"action_output\": \"sparse_categorical_crossentropy\",\n",
    "            \"label_output\": \"sparse_categorical_crossentropy\"\n",
    "        },\n",
    "        metrics={\n",
    "            \"action_output\": [\"accuracy\"],\n",
    "            \"label_output\": [\"accuracy\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # --- 3. Callbacks ---\n",
    "    # Early Stopping configuration as requested:\n",
    "    # Monitor: 'val_action_output_accuracy' (Accuracy of the action prediction on validation set)\n",
    "    # Mode: 'max' (because we want accuracy to increase)\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_action_output_accuracy', \n",
    "        mode='max',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # --- 4. Training ---\n",
    "    print(\"\\nStarting Training...\")\n",
    "    history = model.fit(\n",
    "        x=[X_train_words, X_train_tags],\n",
    "        y=[y_train_act, y_train_dep],\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=([X_val_words, X_val_tags], [y_val_act, y_val_dep]),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1 # Ensures the epoch logs (Epoch 1/10...) are printed\n",
    "    )\n",
    "    \n",
    "    print(f\"--- Training Finished for {model_name} ---\")\n",
    "    return model, history\n",
    "\n",
    "# --- HYPERPARAMETER GRID DEFINITION ---\n",
    "# Expanded grid to test various configurations\n",
    "hyperparameter_grid = [\n",
    "    {\n",
    "        \"word_embed_dim\": 32, \"pos_embed_dim\": 10, \"hidden_units\": 100, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 32, \"dropout_rate\": 0.2,\n",
    "        \"model_name\": \"Base_Model\"\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 64, \"pos_embed_dim\": 20, \"hidden_units\": 200, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 64, \"dropout_rate\": 0.3,\n",
    "        \"model_name\": \"Large_Embeddings_HigherDrop\"\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 32, \"pos_embed_dim\": 10, \"hidden_units\": 100, \n",
    "        \"learning_rate\": 0.0005, \"batch_size\": 32, \"dropout_rate\": 0.2,\n",
    "        \"model_name\": \"Base_SlowLR\" # Slower learning rate for stability\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 16, \"pos_embed_dim\": 5, \"hidden_units\": 50, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 128, \"dropout_rate\": 0.1,\n",
    "        \"model_name\": \"Small_Fast_Model\" # Smaller model, larger batch size\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 64, \"pos_embed_dim\": 10, \"hidden_units\": 150, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 32, \"dropout_rate\": 0.4,\n",
    "        \"model_name\": \"High_Dropout_Regularization\" # Heavy regularization\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 32, \"pos_embed_dim\": 10, \"hidden_units\": 300, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 64, \"dropout_rate\": 0.2,\n",
    "        \"model_name\": \"Wide_Hidden_Layer\" # Large hidden layer capacity\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- EXECUTION LOOP ---\n",
    "\n",
    "all_histories = {}\n",
    "best_val_accuracy = 0.0\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "\n",
    "print(f\"Starting Hyperparameter Search over {len(hyperparameter_grid)} models...\")\n",
    "\n",
    "for params in hyperparameter_grid:\n",
    "    \n",
    "    # Call the function with the current parameters\n",
    "    # Assumes X_train_words, NUM_WORDS, etc., are already defined in the notebook context\n",
    "    model, history = build_and_train_parser(\n",
    "        X_train_words, X_train_tags, y_train_act, y_train_dep,\n",
    "        X_val_words, X_val_tags, y_val_act, y_val_dep,\n",
    "        NUM_WORDS, NUM_TAGS, NUM_ACTIONS, NUM_DEPRELS,\n",
    "        word_embed_dim=params[\"word_embed_dim\"],\n",
    "        pos_embed_dim=params[\"pos_embed_dim\"],\n",
    "        hidden_units=params[\"hidden_units\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        dropout_rate=params[\"dropout_rate\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        epochs=15, # Set max epochs (EarlyStopping will likely cut this shorter)\n",
    "        model_name=params[\"model_name\"]\n",
    "    )\n",
    "    \n",
    "    # Store history\n",
    "    all_histories[params[\"model_name\"]] = history.history\n",
    "    \n",
    "    # Evaluate performance\n",
    "    # We check the best validation accuracy for the action output achieved during training\n",
    "    best_epoch_acc = max(history.history['val_action_output_accuracy'])\n",
    "    print(f\"Result {params['model_name']}: Best Validation Action Accuracy = {best_epoch_acc:.4f}\")\n",
    "    \n",
    "    # Track the global best model\n",
    "    if best_epoch_acc > best_val_accuracy:\n",
    "        print(f\" >> New Best Model Found! (Previous best: {best_val_accuracy:.4f})\")\n",
    "        best_val_accuracy = best_epoch_acc\n",
    "        best_model = model\n",
    "        best_model_name = params[\"model_name\"]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SEARCH COMPLETE\")\n",
    "print(f\"Best Model: '{best_model_name}' with Action Accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# --- SAVE BEST MODEL ---\n",
    "if best_model:\n",
    "    save_filename = f\"{best_model_name}_best.keras\"\n",
    "    print(f\"Saving best model to: {save_filename}\")\n",
    "    best_model.save(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607e03da-ae0c-4780-8631-e86fa98fe7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING HYPERPARAMETER SEARCH ---\n",
      "\n",
      "--- Building Model: Base_Model ---\n",
      "Params: WordEmb=32, PosEmb=10, Hidden=100, LR=0.001, Drop=0.2\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "--- Training Finished for Base_Model ---\n",
      "Result Base_Model: Val Loss=0.7925, Best Action Acc=0.8691\n",
      " >> New Best Model Found! (Previous best loss: inf)\n",
      "\n",
      "--- Building Model: Large_Model_HigherDrop ---\n",
      "Params: WordEmb=64, PosEmb=20, Hidden=200, LR=0.001, Drop=0.3\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "--- Training Finished for Large_Model_HigherDrop ---\n",
      "Result Large_Model_HigherDrop: Val Loss=0.7610, Best Action Acc=0.8696\n",
      " >> New Best Model Found! (Previous best loss: 0.7925)\n",
      "\n",
      "--- Building Model: Base_SlowLR ---\n",
      "Params: WordEmb=32, PosEmb=10, Hidden=100, LR=0.0005, Drop=0.2\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "--- Training Finished for Base_SlowLR ---\n",
      "Result Base_SlowLR: Val Loss=0.8246, Best Action Acc=0.8646\n",
      "\n",
      "--- Building Model: Small_Fast_Model ---\n",
      "Params: WordEmb=16, PosEmb=5, Hidden=50, LR=0.001, Drop=0.1\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "--- Training Finished for Small_Fast_Model ---\n",
      "Result Small_Fast_Model: Val Loss=0.8815, Best Action Acc=0.8563\n",
      "\n",
      "--- SEARCH COMPLETE ---\n",
      "Best Model: 'Large_Model_HigherDrop' with Val Loss: 0.7610\n",
      "Saving best model to: Large_Model_HigherDrop_best.keras\n"
     ]
    }
   ],
   "source": [
    "# --- DEFINICIÓN DE LA PARRILLA DE HIPERPARÁMETROS ---\n",
    "# Puedes añadir o quitar diccionarios para probar más cosas\n",
    "hyperparameter_grid = [\n",
    "    {\n",
    "        \"word_embed_dim\": 32, \"pos_embed_dim\": 10, \"hidden_units\": 100, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 32, \"dropout_rate\": 0.2,\n",
    "        \"model_name\": \"Base_Model\"\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 64, \"pos_embed_dim\": 20, \"hidden_units\": 200, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 64, \"dropout_rate\": 0.3,\n",
    "        \"model_name\": \"Large_Model_HigherDrop\"\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 32, \"pos_embed_dim\": 10, \"hidden_units\": 100, \n",
    "        \"learning_rate\": 0.0005, \"batch_size\": 32, \"dropout_rate\": 0.2,\n",
    "        \"model_name\": \"Base_SlowLR\" # Tasa de aprendizaje más lenta\n",
    "    },\n",
    "    {\n",
    "        \"word_embed_dim\": 16, \"pos_embed_dim\": 5, \"hidden_units\": 50, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 128, \"dropout_rate\": 0.1,\n",
    "        \"model_name\": \"Small_Fast_Model\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- VARIABLES PARA GUARDAR RESULTADOS ---\n",
    "all_histories = {}\n",
    "best_val_loss = float('inf') # Buscamos minimizar la pérdida\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "\n",
    "# --- BUCLE DE ENTRENAMIENTO ---\n",
    "print(\"--- STARTING HYPERPARAMETER SEARCH ---\")\n",
    "\n",
    "for params in hyperparameter_grid:\n",
    "    \n",
    "    # Llamamos a la función con los parámetros actuales\n",
    "    model, history = build_and_train_parser(\n",
    "        X_train_words, X_train_tags, y_train_act, y_train_dep,\n",
    "        X_val_words, X_val_tags, y_val_act, y_val_dep,\n",
    "        NUM_WORDS, NUM_TAGS, NUM_ACTIONS, NUM_DEPRELS,\n",
    "        word_embed_dim=params[\"word_embed_dim\"],\n",
    "        pos_embed_dim=params[\"pos_embed_dim\"],\n",
    "        hidden_units=params[\"hidden_units\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        dropout_rate=params[\"dropout_rate\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        epochs=20, # Un máximo razonable, EarlyStopping cortará antes\n",
    "        model_name=params[\"model_name\"]\n",
    "    )\n",
    "    \n",
    "    # Guardamos el historial\n",
    "    all_histories[params[\"model_name\"]] = history.history\n",
    "    \n",
    "    # Obtenemos la mejor pérdida de validación de este modelo\n",
    "    # 'val_loss' es la suma de las pérdidas de acción y etiqueta\n",
    "    final_val_loss = min(history.history['val_loss'])\n",
    "    final_act_acc = max(history.history['val_action_output_accuracy'])\n",
    "    \n",
    "    print(f\"Result {params['model_name']}: Val Loss={final_val_loss:.4f}, Best Action Acc={final_act_acc:.4f}\")\n",
    "    \n",
    "    # Comprobamos si es el mejor hasta ahora\n",
    "    if final_val_loss < best_val_loss:\n",
    "        print(f\" >> New Best Model Found! (Previous best loss: {best_val_loss:.4f})\")\n",
    "        best_val_loss = final_val_loss\n",
    "        best_model = model\n",
    "        best_model_name = params[\"model_name\"]\n",
    "\n",
    "print(f\"\\n--- SEARCH COMPLETE ---\")\n",
    "print(f\"Best Model: '{best_model_name}' with Val Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# --- GUARDAR EL MEJOR MODELO ---\n",
    "if best_model:\n",
    "    save_filename = f\"{best_model_name}_best.keras\"\n",
    "    print(f\"Saving best model to: {save_filename}\")\n",
    "    best_model.save(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdcef3-8e0c-4b80-8ccd-95dbd0c819cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
