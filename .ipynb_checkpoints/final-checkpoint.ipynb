{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21ffffff-8950-485e-8034-b4e431567151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Data Loading ---\n",
      " Loaded 1748 valid projective sentences for training.\n",
      "\n",
      "--- STEP 2: Generating Samples with the Oracle ---\n",
      "Total samples (game states) generated: 81182\n",
      "Example of Raw Sample (Index 0):\n",
      "   State: Stack (size=1): (0, ROOT, ROOT_UPOS)\n",
      "Buffer (size=13): (1, Distribution, NOUN) | (2, of, ADP) | (3, this, DET) | (4, license, NOUN) | (5, does, AUX) | (6, not, PART) | (7, create, VERB) | (8, an, DET) | (9, attorney, NOUN) | (10, -, PUNCT) | (11, client, NOUN) | (12, relationship, NOUN) | (13, ., PUNCT)\n",
      "Arcs (size=0): set()\n",
      "\n",
      "   Correct Action: SHIFT\n",
      "\n",
      "--- STEP 3: Feature Extraction (Translation to Text) ---\n",
      " Example of Input (X_raw[0]): ['<PAD>', 'ROOT', 'Distribution', 'of', '<PAD>', 'ROOT_UPOS', 'NOUN', 'ADP']\n",
      "   (This is what the network 'sees': words and tags)\n",
      "Example of Output (Y_raw[0]): ('SHIFT', None)\n",
      "   (This is what the network must predict: Action and Label)\n",
      "\n",
      "--- STEP 4: Numerical Conversion (For Keras) ---\n",
      "Vocabulary Sizes:\n",
      "   Unique words: 6872\n",
      "   Unique UPOS tags: 20\n",
      "   Possible actions: 4 {'SHIFT': 0, 'LEFT-ARC': 1, 'RIGHT-ARC': 2, 'REDUCE': 3}\n",
      "   Dependency relations: 44\n",
      "\n",
      "DATA\n",
      "Final numerical example (X_train[0]): [0 2 3 4 0 2 3 4]\n",
      "   (Notice how words are now IDs)\n",
      "Target Action (y_act[0]): 0 -> Corresponds to 'SHIFT'\n",
      "Target Action (y_act[0]): 0 -> Corresponds to 'SHIFT'\n",
      "Data saved to 'training_data.npz' and 'vocabs.pkl'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from conllu_reader import ConlluReader\n",
    "from algorithm import ArcEager\n",
    "import pickle\n",
    "\n",
    "# --- 1. LOAD DATA (Use the TRAIN file, not test) ---\n",
    "print(\"--- STEP 1: Data Loading ---\")\n",
    "reader = ConlluReader()\n",
    "# Ensure the filename matches your specific training file path\n",
    "train_sentences = reader.read_conllu_file(\"en_partut-ud-train_clean.conllu\") \n",
    "\n",
    "# Filter out non-projective trees as Arc-Eager cannot handle them [cite: 1100]\n",
    "train_sentences = reader.remove_non_projective_trees(train_sentences)\n",
    "print(f\" Loaded {len(train_sentences)} valid projective sentences for training.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. OBTAIN RAW SAMPLES (Oracle Execution) ---\n",
    "print(\"--- STEP 2: Generating Samples with the Oracle ---\")\n",
    "arc_eager = ArcEager()\n",
    "raw_samples = []\n",
    "\n",
    "for sent in train_sentences:\n",
    "    try:\n",
    "        # The oracle returns a list of Sample objects (State + Transition) for this sentence\n",
    "        samples = arc_eager.oracle(sent)\n",
    "        raw_samples.extend(samples)\n",
    "    except AssertionError:\n",
    "        # If the oracle fails to reconstruct the exact gold tree, skip the sentence\n",
    "        continue\n",
    "\n",
    "print(f\"Total samples (game states) generated: {len(raw_samples)}\")\n",
    "\n",
    "# VISUALIZATION: Let's see what a raw sample looks like\n",
    "if raw_samples:\n",
    "    print(f\"Example of Raw Sample (Index 0):\")\n",
    "    print(f\"   State: {raw_samples[0].state}\")\n",
    "    print(f\"   Correct Action: {raw_samples[0].transition}\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "# --- 3. FEATURE EXTRACTION (From State to List of Strings) ---\n",
    "# We need to extract features from the stack and buffer [cite: 934, 1080]\n",
    "print(\"--- STEP 3: Feature Extraction (Translation to Text) ---\")\n",
    "X_raw = [] # Stores lists of words/tags (Input features)\n",
    "Y_raw = [] # Stores actions and dependencies (Outputs)\n",
    "\n",
    "for sample in raw_samples:\n",
    "    # Extract features (words and UPOS tags) using the implemented function\n",
    "    # nbuffer_feats=2 and nstack_feats=2 is the suggested configuration [cite: 1091]\n",
    "    features = sample.state_to_feats(nbuffer_feats=2, nstack_feats=2)\n",
    "    X_raw.append(features)\n",
    "    \n",
    "    # Save the action (transition) and the dependency label\n",
    "    action_name = sample.transition.action\n",
    "    dep_label = sample.transition.dependency\n",
    "    Y_raw.append((action_name, dep_label))\n",
    "\n",
    "# VISUALIZATION: What do the lists contain now?\n",
    "print(f\" Example of Input (X_raw[0]): {X_raw[0]}\")\n",
    "print(f\"   (This is what the network 'sees': words and tags)\")\n",
    "print(f\"Example of Output (Y_raw[0]): {Y_raw[0]}\")\n",
    "print(f\"   (This is what the network must predict: Action and Label)\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 4. PREPARATION FOR KERAS (Vocabularies and Numerical Conversion) ---\n",
    "# Neural networks require numerical input [cite: 733]\n",
    "print(\"--- STEP 4: Numerical Conversion (For Keras) ---\")\n",
    "\n",
    "# 4.1 Create Dictionaries (Text -> Number Maps)\n",
    "words_vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "upos_vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "actions_vocab = {}  # E.g., 'SHIFT': 0, 'LEFT-ARC': 1...\n",
    "deprels_vocab = {None: 0} # E.g., 'nsubj': 1, 'det': 2...\n",
    "\n",
    "# Fill vocabularies by iterating through all collected data\n",
    "for features in X_raw:\n",
    "    # Assuming features structure: [W_s2, W_s1, W_b1, W_b2, P_s2, P_s1, P_b1, P_b2]\n",
    "    # The first half are words, the second half are UPOS tags\n",
    "    num_words = len(features) // 2 \n",
    "    \n",
    "    words = features[:num_words]\n",
    "    upos = features[num_words:]\n",
    "    \n",
    "    for w in words:\n",
    "        if w not in words_vocab:\n",
    "            words_vocab[w] = len(words_vocab)\n",
    "    for u in upos:\n",
    "        if u not in upos_vocab:\n",
    "            upos_vocab[u] = len(upos_vocab)\n",
    "\n",
    "for act, dep in Y_raw:\n",
    "    if act not in actions_vocab:\n",
    "        actions_vocab[act] = len(actions_vocab)\n",
    "    if dep not in deprels_vocab:\n",
    "        deprels_vocab[dep] = len(deprels_vocab)\n",
    "\n",
    "print(f\"Vocabulary Sizes:\")\n",
    "print(f\"   Unique words: {len(words_vocab)}\")\n",
    "print(f\"   Unique UPOS tags: {len(upos_vocab)}\")\n",
    "print(f\"   Possible actions: {len(actions_vocab)} {actions_vocab}\")\n",
    "print(f\"   Dependency relations: {len(deprels_vocab)}\\n\")\n",
    "\n",
    "# 4.2 Convert everything to Numbers (Matrices for Keras)\n",
    "# X_train will have shape (Num_Samples, Num_Features)\n",
    "X_train_numerical = []\n",
    "Y_train_actions = []\n",
    "Y_train_deprels = []\n",
    "\n",
    "for i in range(len(X_raw)):\n",
    "    # Convert INPUT (Features)\n",
    "    features = X_raw[i]\n",
    "    num_vec = []\n",
    "    \n",
    "    # Convert words to IDs\n",
    "    num_words = len(features) // 2\n",
    "    for w in features[:num_words]:\n",
    "        num_vec.append(words_vocab.get(w, words_vocab['<UNK>']))\n",
    "    # Convert UPOS tags to IDs\n",
    "    for u in features[num_words:]:\n",
    "        num_vec.append(upos_vocab.get(u, upos_vocab['<UNK>']))\n",
    "    \n",
    "    X_train_numerical.append(num_vec)\n",
    "    \n",
    "    # Convert OUTPUT (Targets)\n",
    "    act, dep = Y_raw[i]\n",
    "    Y_train_actions.append(actions_vocab[act])\n",
    "    # Use 0 if the dependency is None (e.g., for SHIFT or REDUCE)\n",
    "    Y_train_deprels.append(deprels_vocab.get(dep, 0)) \n",
    "\n",
    "# Convert to Numpy arrays (The actual input format Keras expects)\n",
    "X_train = np.array(X_train_numerical)\n",
    "y_act = np.array(Y_train_actions)\n",
    "y_dep = np.array(Y_train_deprels)\n",
    "\n",
    "print(\"DATA\")\n",
    "print(f\"Final numerical example (X_train[0]): {X_train[0]}\")\n",
    "print(f\"   (Notice how words are now IDs)\")\n",
    "# Find the action name corresponding to the ID for display purposes\n",
    "act_name = list(actions_vocab.keys())[list(actions_vocab.values()).index(y_act[0])]\n",
    "print(f\"Target Action (y_act[0]): {y_act[0]} -> Corresponds to '{act_name}'\")\n",
    "\n",
    "print(f\"Target Action (y_act[0]): {y_act[0]} -> Corresponds to '{act_name}'\")\n",
    "np.savez(\"training_data.npz\", X=X_train, y_act=y_act, y_dep=y_dep)\n",
    "with open(\"vocabs.pkl\", \"wb\") as f:\n",
    "    pickle.dump((words_vocab, upos_vocab, actions_vocab, deprels_vocab), f)\n",
    "print(\"Data saved to 'training_data.npz' and 'vocabs.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb1ddac6-d194-43c9-b780-f57962b6a357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Loading Training Data and Vocabularies ---\n",
      "Training samples: 73063\n",
      "Validation samples: 8119\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import pickle\n",
    "\n",
    "# --- 1. LOAD PREPARED DATA ---\n",
    "print(\"--- STEP 1: Loading Training Data and Vocabularies ---\")\n",
    "\n",
    "try:\n",
    "    data = np.load(\"training_data.npz\")\n",
    "    X_train_full = data['X']      # Shape: (Num_Samples, 8) -> 4 words + 4 tags\n",
    "    y_train_act_full = data['y_act']   # Shape: (Num_Samples,) -> Action IDs\n",
    "    y_train_dep_full = data['y_dep']   # Shape: (Num_Samples,) -> Dependency IDs\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'training_data.npz' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Load vocabularies\n",
    "try:\n",
    "    with open(\"vocabs.pkl\", \"rb\") as f:\n",
    "        words_vocab, upos_vocab, actions_vocab, deprels_vocab = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'vocabs.pkl' not found.\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Splitting ---\n",
    "split_idx = int(len(X_train_full) * 0.9)\n",
    "\n",
    "# Inputs\n",
    "X_train, X_val = X_train_full[:split_idx], X_train_full[split_idx:]\n",
    "\n",
    "# Outputs (We need TWO sets of targets now)\n",
    "y_train_act, y_val_act = y_train_act_full[:split_idx], y_train_act_full[split_idx:]\n",
    "y_train_dep, y_val_dep = y_train_dep_full[:split_idx], y_train_dep_full[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "\n",
    "# --- 2. SEPARATE INPUTS (Words vs Tags) ---\n",
    "# X contains [Word_S2, Word_S1, Word_B1, Word_B2, Tag_S2, Tag_S1, Tag_B1, Tag_B2]\n",
    "num_features_total = X_train.shape[1]\n",
    "num_word_feats = num_features_total // 2 \n",
    "\n",
    "X_train_words = X_train[:, :num_word_feats]\n",
    "X_train_tags  = X_train[:, num_word_feats:]\n",
    "\n",
    "X_val_words = X_val[:, :num_word_feats]\n",
    "X_val_tags  = X_val[:, num_word_feats:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7247108-9526-4bd4-bb08-b210a3addd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1 (Actions): 4 classes\n",
      "Output 2 (Labels): 44 classes\n",
      "--- STEP 2: Building Multi-Output Neural Network ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ArcEager_MultiOutput_Parser\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ArcEager_MultiOutput_Parser\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,936</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">252</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,300</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_shared[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,444</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │    \u001b[38;5;34m219,936\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m210\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m252\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_shared       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m25,300\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_shared[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m404\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m4,444\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,294</span> (977.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m250,294\u001b[0m (977.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,294</span> (977.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m250,294\u001b[0m (977.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3. DEFINE HYPERPARAMETERS ---\n",
    "WORD_EMBED_DIM = 32\n",
    "POS_EMBED_DIM = 10\n",
    "HIDDEN_UNITS = 100\n",
    "\n",
    "NUM_WORDS = len(words_vocab) + 1\n",
    "NUM_TAGS = len(upos_vocab) + 1\n",
    "NUM_ACTIONS = len(actions_vocab)  # Output 1 size (e.g., 4: SHIFT, REDUCE, LA, RA)\n",
    "NUM_DEPRELS = len(deprels_vocab)  # Output 2 size (e.g., 44 dependency labels)\n",
    "\n",
    "print(f\"Output 1 (Actions): {NUM_ACTIONS} classes\")\n",
    "print(f\"Output 2 (Labels): {NUM_DEPRELS} classes\")\n",
    "\n",
    "\n",
    "# --- 4. BUILD THE MODEL (Multi-Output) ---\n",
    "print(\"--- STEP 2: Building Multi-Output Neural Network ---\")\n",
    "\n",
    "# A. Input Layers\n",
    "input_words = layers.Input(shape=(num_word_feats,), name=\"input_words\")\n",
    "input_tags  = layers.Input(shape=(num_word_feats,), name=\"input_tags\")\n",
    "\n",
    "# B. Embedding Layers\n",
    "embed_words = layers.Embedding(input_dim=NUM_WORDS, output_dim=WORD_EMBED_DIM, name=\"embed_words\")(input_words)\n",
    "embed_tags  = layers.Embedding(input_dim=NUM_TAGS, output_dim=POS_EMBED_DIM, name=\"embed_tags\")(input_tags)\n",
    "\n",
    "# C. Flatten & Concatenate\n",
    "flat_words = layers.Flatten()(embed_words)\n",
    "flat_tags  = layers.Flatten()(embed_tags)\n",
    "merged = layers.Concatenate(name=\"concat_features\")([flat_words, flat_tags])\n",
    "\n",
    "# D. Shared Hidden Layers\n",
    "# This layer learns features relevant for BOTH tasks (action and label prediction)\n",
    "hidden = layers.Dense(HIDDEN_UNITS, activation='relu', name=\"hidden_shared\")(merged)\n",
    "hidden = layers.Dropout(0.2)(hidden)\n",
    "\n",
    "# E. Output Layers (The Two Heads)\n",
    "# Head 1: Predicts the transition action (SHIFT, REDUCE, etc.)\n",
    "output_action = layers.Dense(NUM_ACTIONS, activation='softmax', name=\"action_output\")(hidden)\n",
    "\n",
    "# Head 2: Predicts the dependency label (nsubj, det, etc.)\n",
    "output_label = layers.Dense(NUM_DEPRELS, activation='softmax', name=\"label_output\")(hidden)\n",
    "\n",
    "# Create Model with 2 inputs and 2 outputs\n",
    "model = models.Model(\n",
    "    inputs=[input_words, input_tags], \n",
    "    outputs=[output_action, output_label], \n",
    "    name=\"ArcEager_MultiOutput_Parser\"\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637b5324-e222-4723-a04a-88b97d478d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Search over 4 models...\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: Balanced_Deep_Model\n",
      "Params: WordEmb=100, PosEmb=25, Hidden=256, LR=0.001, Drop=0.3, Batch=64\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Balanced_Deep_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Balanced_Deep_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">687,300</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">192,256</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,676</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │    \u001b[38;5;34m687,300\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m25\u001b[0m)     │        \u001b[38;5;34m525\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m750\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_1 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m192,256\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_2 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m5,676\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">919,169</span> (3.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m919,169\u001b[0m (3.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">919,169</span> (3.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m919,169\u001b[0m (3.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - action_output_accuracy: 0.8232 - action_output_loss: 0.4558 - label_output_accuracy: 0.7616 - label_output_loss: 0.8474 - loss: 1.3031 - val_action_output_accuracy: 0.8797 - val_action_output_loss: 0.3112 - val_label_output_accuracy: 0.8379 - val_label_output_loss: 0.4611 - val_loss: 0.7726\n",
      "Epoch 2/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - action_output_accuracy: 0.9126 - action_output_loss: 0.2362 - label_output_accuracy: 0.8688 - label_output_loss: 0.3997 - loss: 0.6358 - val_action_output_accuracy: 0.8763 - val_action_output_loss: 0.3305 - val_label_output_accuracy: 0.8540 - val_label_output_loss: 0.4250 - val_loss: 0.7559\n",
      "Epoch 3/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - action_output_accuracy: 0.9472 - action_output_loss: 0.1481 - label_output_accuracy: 0.9055 - label_output_loss: 0.2789 - loss: 0.4270 - val_action_output_accuracy: 0.8726 - val_action_output_loss: 0.3785 - val_label_output_accuracy: 0.8564 - val_label_output_loss: 0.4585 - val_loss: 0.8374\n",
      "Epoch 4/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - action_output_accuracy: 0.9633 - action_output_loss: 0.1024 - label_output_accuracy: 0.9322 - label_output_loss: 0.2047 - loss: 0.3071 - val_action_output_accuracy: 0.8738 - val_action_output_loss: 0.4505 - val_label_output_accuracy: 0.8511 - val_label_output_loss: 0.5129 - val_loss: 0.9639\n",
      "Epoch 5/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - action_output_accuracy: 0.9736 - action_output_loss: 0.0754 - label_output_accuracy: 0.9489 - label_output_loss: 0.1569 - loss: 0.2324 - val_action_output_accuracy: 0.8669 - val_action_output_loss: 0.5014 - val_label_output_accuracy: 0.8483 - val_label_output_loss: 0.5807 - val_loss: 1.0827\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Training Finished for Balanced_Deep_Model ---\n",
      "Result Balanced_Deep_Model: Best Validation Action Accuracy = 0.8797\n",
      " >> New Best Model Found! (Previous best: 0.0000)\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: High_Capacity_Model\n",
      "Params: WordEmb=200, PosEmb=50, Hidden=512, LR=0.001, Drop=0.4, Batch=128\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"High_Capacity_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"High_Capacity_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,374,600</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">768,512</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,308</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m200\u001b[0m)    │  \u001b[38;5;34m1,374,600\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │      \u001b[38;5;34m1,050\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_1 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m768,512\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_2 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │      \u001b[38;5;34m1,028\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │     \u001b[38;5;34m11,308\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,287,826</span> (8.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,287,826\u001b[0m (8.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,287,826</span> (8.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,287,826\u001b[0m (8.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - action_output_accuracy: 0.8263 - action_output_loss: 0.4504 - label_output_accuracy: 0.7690 - label_output_loss: 0.8250 - loss: 1.2756 - val_action_output_accuracy: 0.8827 - val_action_output_loss: 0.3076 - val_label_output_accuracy: 0.8495 - val_label_output_loss: 0.4362 - val_loss: 0.7464\n",
      "Epoch 2/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - action_output_accuracy: 0.9181 - action_output_loss: 0.2267 - label_output_accuracy: 0.8735 - label_output_loss: 0.3807 - loss: 0.6074 - val_action_output_accuracy: 0.8859 - val_action_output_loss: 0.3164 - val_label_output_accuracy: 0.8483 - val_label_output_loss: 0.4281 - val_loss: 0.7473\n",
      "Epoch 3/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - action_output_accuracy: 0.9518 - action_output_loss: 0.1352 - label_output_accuracy: 0.9150 - label_output_loss: 0.2545 - loss: 0.3897 - val_action_output_accuracy: 0.8771 - val_action_output_loss: 0.3738 - val_label_output_accuracy: 0.8542 - val_label_output_loss: 0.4622 - val_loss: 0.8388\n",
      "Epoch 4/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - action_output_accuracy: 0.9677 - action_output_loss: 0.0906 - label_output_accuracy: 0.9419 - label_output_loss: 0.1778 - loss: 0.2683 - val_action_output_accuracy: 0.8766 - val_action_output_loss: 0.4265 - val_label_output_accuracy: 0.8558 - val_label_output_loss: 0.5068 - val_loss: 0.9368\n",
      "Epoch 5/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - action_output_accuracy: 0.9756 - action_output_loss: 0.0679 - label_output_accuracy: 0.9584 - label_output_loss: 0.1300 - loss: 0.1978 - val_action_output_accuracy: 0.8694 - val_action_output_loss: 0.4933 - val_label_output_accuracy: 0.8506 - val_label_output_loss: 0.5839 - val_loss: 1.0818\n",
      "Epoch 6/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - action_output_accuracy: 0.9817 - action_output_loss: 0.0529 - label_output_accuracy: 0.9685 - label_output_loss: 0.0975 - loss: 0.1503 - val_action_output_accuracy: 0.8724 - val_action_output_loss: 0.5519 - val_label_output_accuracy: 0.8516 - val_label_output_loss: 0.6602 - val_loss: 1.2165\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "--- Training Finished for High_Capacity_Model ---\n",
      "Result High_Capacity_Model: Best Validation Action Accuracy = 0.8859\n",
      " >> New Best Model Found! (Previous best: 0.8797)\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: Fine_Tuned_Slow_Learner\n",
      "Params: WordEmb=100, PosEmb=25, Hidden=300, LR=0.0005, Drop=0.3, Batch=32\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Fine_Tuned_Slow_Learner\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Fine_Tuned_Slow_Learner\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">687,300</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">225,300</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">45,150</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">604</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,644</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │    \u001b[38;5;34m687,300\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m25\u001b[0m)     │        \u001b[38;5;34m525\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m750\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_1 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │    \u001b[38;5;34m225,300\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_2 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │     \u001b[38;5;34m45,150\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m604\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m6,644\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">965,523</span> (3.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m965,523\u001b[0m (3.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">965,523</span> (3.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m965,523\u001b[0m (3.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/25\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - action_output_accuracy: 0.8225 - action_output_loss: 0.4632 - label_output_accuracy: 0.7614 - label_output_loss: 0.8629 - loss: 1.3262 - val_action_output_accuracy: 0.8770 - val_action_output_loss: 0.3208 - val_label_output_accuracy: 0.8364 - val_label_output_loss: 0.4699 - val_loss: 0.7913\n",
      "Epoch 2/25\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - action_output_accuracy: 0.9081 - action_output_loss: 0.2511 - label_output_accuracy: 0.8625 - label_output_loss: 0.4237 - loss: 0.6748 - val_action_output_accuracy: 0.8802 - val_action_output_loss: 0.3230 - val_label_output_accuracy: 0.8517 - val_label_output_loss: 0.4282 - val_loss: 0.7518\n",
      "Epoch 3/25\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - action_output_accuracy: 0.9429 - action_output_loss: 0.1592 - label_output_accuracy: 0.9019 - label_output_loss: 0.2981 - loss: 0.4572 - val_action_output_accuracy: 0.8670 - val_action_output_loss: 0.3732 - val_label_output_accuracy: 0.8459 - val_label_output_loss: 0.4632 - val_loss: 0.8371\n",
      "Epoch 4/25\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - action_output_accuracy: 0.9622 - action_output_loss: 0.1061 - label_output_accuracy: 0.9267 - label_output_loss: 0.2203 - loss: 0.3264 - val_action_output_accuracy: 0.8729 - val_action_output_loss: 0.4157 - val_label_output_accuracy: 0.8504 - val_label_output_loss: 0.4916 - val_loss: 0.9082\n",
      "Epoch 5/25\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - action_output_accuracy: 0.9730 - action_output_loss: 0.0775 - label_output_accuracy: 0.9471 - label_output_loss: 0.1624 - loss: 0.2400 - val_action_output_accuracy: 0.8673 - val_action_output_loss: 0.4773 - val_label_output_accuracy: 0.8439 - val_label_output_loss: 0.5643 - val_loss: 1.0425\n",
      "Epoch 6/25\n",
      "\u001b[1m2284/2284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - action_output_accuracy: 0.9796 - action_output_loss: 0.0578 - label_output_accuracy: 0.9595 - label_output_loss: 0.1233 - loss: 0.1811 - val_action_output_accuracy: 0.8725 - val_action_output_loss: 0.5404 - val_label_output_accuracy: 0.8507 - val_label_output_loss: 0.6133 - val_loss: 1.1549\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "--- Training Finished for Fine_Tuned_Slow_Learner ---\n",
      "Result Fine_Tuned_Slow_Learner: Best Validation Action Accuracy = 0.8802\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL: High_Regularization_Model\n",
      "Params: WordEmb=100, PosEmb=25, Hidden=256, LR=0.001, Drop=0.5, Batch=64\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"High_Regularization_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"High_Regularization_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">687,300</span> │ input_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span> │ input_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_words[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_tags[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">192,256</span> │ concat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ hidden_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,676</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_words         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │    \u001b[38;5;34m687,300\u001b[0m │ input_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed_tags          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m25\u001b[0m)     │        \u001b[38;5;34m525\u001b[0m │ input_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_words       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_words[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_tags        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embed_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m750\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_words[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_tags[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_1 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m192,256\u001b[0m │ concat_features[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden_2 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ hidden_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ label_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │      \u001b[38;5;34m5,676\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">919,169</span> (3.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m919,169\u001b[0m (3.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">919,169</span> (3.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m919,169\u001b[0m (3.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - action_output_accuracy: 0.8057 - action_output_loss: 0.5140 - label_output_accuracy: 0.7247 - label_output_loss: 0.9961 - loss: 1.5103 - val_action_output_accuracy: 0.8706 - val_action_output_loss: 0.3379 - val_label_output_accuracy: 0.8303 - val_label_output_loss: 0.5088 - val_loss: 0.8470\n",
      "Epoch 2/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - action_output_accuracy: 0.8927 - action_output_loss: 0.2956 - label_output_accuracy: 0.8391 - label_output_loss: 0.5119 - loss: 0.8074 - val_action_output_accuracy: 0.8768 - val_action_output_loss: 0.3294 - val_label_output_accuracy: 0.8423 - val_label_output_loss: 0.4506 - val_loss: 0.7803\n",
      "Epoch 3/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - action_output_accuracy: 0.9265 - action_output_loss: 0.2088 - label_output_accuracy: 0.8756 - label_output_loss: 0.3873 - loss: 0.5960 - val_action_output_accuracy: 0.8719 - val_action_output_loss: 0.3673 - val_label_output_accuracy: 0.8505 - val_label_output_loss: 0.4707 - val_loss: 0.8385\n",
      "Epoch 4/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - action_output_accuracy: 0.9453 - action_output_loss: 0.1550 - label_output_accuracy: 0.8986 - label_output_loss: 0.3097 - loss: 0.4645 - val_action_output_accuracy: 0.8718 - val_action_output_loss: 0.3988 - val_label_output_accuracy: 0.8478 - val_label_output_loss: 0.4985 - val_loss: 0.8977\n",
      "Epoch 5/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - action_output_accuracy: 0.9572 - action_output_loss: 0.1245 - label_output_accuracy: 0.9136 - label_output_loss: 0.2585 - loss: 0.3831 - val_action_output_accuracy: 0.8701 - val_action_output_loss: 0.4646 - val_label_output_accuracy: 0.8481 - val_label_output_loss: 0.5570 - val_loss: 1.0223\n",
      "Epoch 6/25\n",
      "\u001b[1m1142/1142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - action_output_accuracy: 0.9643 - action_output_loss: 0.1025 - label_output_accuracy: 0.9270 - label_output_loss: 0.2202 - loss: 0.3227 - val_action_output_accuracy: 0.8710 - val_action_output_loss: 0.5176 - val_label_output_accuracy: 0.8494 - val_label_output_loss: 0.5876 - val_loss: 1.1059\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "--- Training Finished for High_Regularization_Model ---\n",
      "Result High_Regularization_Model: Best Validation Action Accuracy = 0.8768\n",
      "\n",
      "============================================================\n",
      "SEARCH COMPLETE\n",
      "Best Model: 'High_Capacity_Model' with Action Accuracy: 0.8859\n",
      "============================================================\n",
      "\n",
      "Saving best model to: High_Capacity_Model_best.keras\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_and_train_parser(\n",
    "    # Input Data\n",
    "    X_train_words, X_train_tags, y_train_act, y_train_dep,\n",
    "    X_val_words, X_val_tags, y_val_act, y_val_dep,\n",
    "    # Fixed Dimensions (Vocabularies)\n",
    "    num_words, num_tags, num_actions, num_deprels,\n",
    "    # Hyperparameters (Variables)\n",
    "    word_embed_dim=100, # Aumentado el default\n",
    "    pos_embed_dim=25,   # Aumentado el default\n",
    "    hidden_units=200,   # Aumentado el default\n",
    "    learning_rate=0.001,\n",
    "    dropout_rate=0.3,\n",
    "    batch_size=64,\n",
    "    epochs=30,          # Más épocas (el EarlyStopping cortará si es necesario)\n",
    "    model_name=\"Parser_Model\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds, compiles, and trains a multi-output neural network for dependency parsing.\n",
    "    NOW IMPROVED WITH A DEEPER ARCHITECTURE.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING MODEL: {model_name}\")\n",
    "    print(f\"Params: WordEmb={word_embed_dim}, PosEmb={pos_embed_dim}, Hidden={hidden_units}, LR={learning_rate}, Drop={dropout_rate}, Batch={batch_size}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # --- 1. Architecture ---\n",
    "    \n",
    "    # Input Layers\n",
    "    input_words = layers.Input(shape=(X_train_words.shape[1],), name=\"input_words\")\n",
    "    input_tags  = layers.Input(shape=(X_train_tags.shape[1],), name=\"input_tags\")\n",
    "\n",
    "    # Embedding Layers\n",
    "    embed_words = layers.Embedding(input_dim=num_words, output_dim=word_embed_dim, name=\"embed_words\")(input_words)\n",
    "    embed_tags  = layers.Embedding(input_dim=num_tags, output_dim=pos_embed_dim, name=\"embed_tags\")(input_tags)\n",
    "\n",
    "    # Flattening\n",
    "    flat_words = layers.Flatten(name=\"flatten_words\")(embed_words)\n",
    "    flat_tags  = layers.Flatten(name=\"flatten_tags\")(embed_tags)\n",
    "\n",
    "    # Concatenation\n",
    "    merged = layers.Concatenate(name=\"concat_features\")([flat_words, flat_tags])\n",
    "\n",
    "    # --- MEJORA: ARQUITECTURA PROFUNDA (Deep Network) ---\n",
    "    \n",
    "    # Hidden Layer 1\n",
    "    hidden = layers.Dense(hidden_units, activation='relu', name=\"hidden_1\")(merged)\n",
    "    if dropout_rate > 0:\n",
    "        hidden = layers.Dropout(dropout_rate, name=\"dropout_1\")(hidden)\n",
    "\n",
    "    # Hidden Layer 2 (NUEVA)\n",
    "    # Añadimos una segunda capa para refinar las características aprendidas\n",
    "    # Usamos la mitad de neuronas que la capa anterior (estructura de embudo)\n",
    "    hidden_2_units = max(hidden_units // 2, 50) # Aseguramos mínimo 50 neuronas\n",
    "    hidden = layers.Dense(hidden_2_units, activation='relu', name=\"hidden_2\")(hidden)\n",
    "    if dropout_rate > 0:\n",
    "        hidden = layers.Dropout(dropout_rate, name=\"dropout_2\")(hidden)\n",
    "\n",
    "    # Output Layers (Two Heads)\n",
    "    output_action = layers.Dense(num_actions, activation='softmax', name=\"action_output\")(hidden)\n",
    "    output_label = layers.Dense(num_deprels, activation='softmax', name=\"label_output\")(hidden)\n",
    "\n",
    "    # Create the Model\n",
    "    model = models.Model(\n",
    "        inputs=[input_words, input_tags], \n",
    "        outputs=[output_action, output_label], \n",
    "        name=model_name\n",
    "    )\n",
    "\n",
    "    # Print Model Summary\n",
    "    model.summary()\n",
    "\n",
    "    # --- 2. Compilation ---\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss={\n",
    "            \"action_output\": \"sparse_categorical_crossentropy\",\n",
    "            \"label_output\": \"sparse_categorical_crossentropy\"\n",
    "        },\n",
    "        metrics={\n",
    "            \"action_output\": [\"accuracy\"],\n",
    "            \"label_output\": [\"accuracy\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # --- 3. Callbacks ---\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_action_output_accuracy', \n",
    "        mode='max',\n",
    "        patience=4, # Un poco más de paciencia para modelos grandes\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # --- 4. Training ---\n",
    "    print(\"\\nStarting Training...\")\n",
    "    history = model.fit(\n",
    "        x=[X_train_words, X_train_tags],\n",
    "        y=[y_train_act, y_train_dep],\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=([X_val_words, X_val_tags], [y_val_act, y_val_dep]),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"--- Training Finished for {model_name} ---\")\n",
    "    return model, history\n",
    "\n",
    "# --- HYPERPARAMETER GRID DEFINITION (MEJORADA) ---\n",
    "# Configuraciones diseñadas para maximizar el accuracy\n",
    "hyperparameter_grid = [\n",
    "    # 1. Una configuración equilibrada pero potente\n",
    "    {\n",
    "        \"word_embed_dim\": 100, \"pos_embed_dim\": 25, \"hidden_units\": 256, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 64, \"dropout_rate\": 0.3,\n",
    "        \"model_name\": \"Balanced_Deep_Model\"\n",
    "    },\n",
    "    # 2. \"La Bestia\": Embeddings muy grandes y mucha capacidad (Cuidado con la memoria RAM)\n",
    "    {\n",
    "        \"word_embed_dim\": 200, \"pos_embed_dim\": 50, \"hidden_units\": 512, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 128, \"dropout_rate\": 0.4,\n",
    "        \"model_name\": \"High_Capacity_Model\"\n",
    "    },\n",
    "    # 3. Ajuste fino: Tasa de aprendizaje más lenta para encontrar el mínimo global mejor\n",
    "    {\n",
    "        \"word_embed_dim\": 100, \"pos_embed_dim\": 25, \"hidden_units\": 300, \n",
    "        \"learning_rate\": 0.0005, \"batch_size\": 32, \"dropout_rate\": 0.3,\n",
    "        \"model_name\": \"Fine_Tuned_Slow_Learner\"\n",
    "    },\n",
    "    # 4. Mucha regularización: Útil si ves que el Training Acc es 99% pero Val Acc es bajo\n",
    "    {\n",
    "        \"word_embed_dim\": 100, \"pos_embed_dim\": 25, \"hidden_units\": 256, \n",
    "        \"learning_rate\": 0.001, \"batch_size\": 64, \"dropout_rate\": 0.5,\n",
    "        \"model_name\": \"High_Regularization_Model\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- EXECUTION LOOP ---\n",
    "\n",
    "all_histories = {}\n",
    "best_val_accuracy = 0.0\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "\n",
    "print(f\"Starting Hyperparameter Search over {len(hyperparameter_grid)} models...\")\n",
    "\n",
    "for params in hyperparameter_grid:\n",
    "    \n",
    "    # Call the function\n",
    "    model, history = build_and_train_parser(\n",
    "        X_train_words, X_train_tags, y_train_act, y_train_dep,\n",
    "        X_val_words, X_val_tags, y_val_act, y_val_dep,\n",
    "        NUM_WORDS, NUM_TAGS, NUM_ACTIONS, NUM_DEPRELS,\n",
    "        word_embed_dim=params[\"word_embed_dim\"],\n",
    "        pos_embed_dim=params[\"pos_embed_dim\"],\n",
    "        hidden_units=params[\"hidden_units\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        dropout_rate=params[\"dropout_rate\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        epochs=25, \n",
    "        model_name=params[\"model_name\"]\n",
    "    )\n",
    "    \n",
    "    all_histories[params[\"model_name\"]] = history.history\n",
    "    \n",
    "    # Evaluate performance based on Action Accuracy\n",
    "    best_epoch_acc = max(history.history['val_action_output_accuracy'])\n",
    "    print(f\"Result {params['model_name']}: Best Validation Action Accuracy = {best_epoch_acc:.4f}\")\n",
    "    \n",
    "    if best_epoch_acc > best_val_accuracy:\n",
    "        print(f\" >> New Best Model Found! (Previous best: {best_val_accuracy:.4f})\")\n",
    "        best_val_accuracy = best_epoch_acc\n",
    "        best_model = model\n",
    "        best_model_name = params[\"model_name\"]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SEARCH COMPLETE\")\n",
    "print(f\"Best Model: '{best_model_name}' with Action Accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# --- SAVE BEST MODEL ---\n",
    "if best_model:\n",
    "    save_filename = f\"{best_model_name}_best.keras\"\n",
    "    print(f\"Saving best model to: {save_filename}\")\n",
    "    best_model.save(save_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac1ad3-ae51-4b56-9419-557ac9e7b74b",
   "metadata": {},
   "source": [
    "## 5. Inference (Decoding) and Evaluation\n",
    "\n",
    "Una vez tenemos nuestro modelo entrenado (y guardado como .keras), llega el momento de usarlo para procesar datos nuevos (Test Set) y construir los árboles sintácticos.\n",
    "\n",
    "Para hacer esto de manera eficiente, implementaremos una estrategia de Decodificación Vertical (Vertical Decoding). En lugar de procesar una oración completa hasta el final antes de pasar a la siguiente (Horizontal), procesamos un lote (batch) de oraciones simultáneamente.\n",
    "\n",
    "1. Extraemos el estado actual de todas las oraciones activas en el lote.\n",
    "\n",
    "2. La red neuronal predice la siguiente acción para todo el lote en una sola operación matricial (mucho más rápido para la GPU/CPU).\n",
    "\n",
    "3. Aplicamos las transiciones correspondientes a cada oración.\n",
    "\n",
    "4. Si una oración termina, sale del lote activo.\n",
    "    \n",
    "5. Repetimos hasta que todas las oraciones del lote hayan terminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab78f657-e001-4756-8a70-04c490dc7905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Loading Resources for Inference ---\n",
      "Loaded 153 test sentences.\n",
      "Loading model from: High_Capacity_Model_best.keras\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from conllu_reader import ConlluReader\n",
    "from algorithm import ArcEager, Transition\n",
    "from postprocessor import PostProcessor\n",
    "\n",
    "# --- 1. CARGA DE RECURSOS ---\n",
    "print(\"--- STEP 1: Loading Resources for Inference ---\")\n",
    "\n",
    "# 1. Cargar datos de TEST (No los usamos para entrenar, solo para evaluar)\n",
    "reader = ConlluReader()\n",
    "# Asegúrate de que el nombre del archivo sea correcto\n",
    "test_sentences = reader.read_conllu_file(\"en_partut-ud-test_clean.conllu\") \n",
    "print(f\"Loaded {len(test_sentences)} test sentences.\")\n",
    "\n",
    "# 2. Cargar Vocabularios (Deben ser los MISMOS que en el entrenamiento)\n",
    "with open(\"vocabs.pkl\", \"rb\") as f:\n",
    "    words_vocab, upos_vocab, actions_vocab, deprels_vocab = pickle.load(f)\n",
    "\n",
    "# Invertir vocabularios para decodificar (Necesitamos pasar de ID -> Texto)\n",
    "id_to_action = {v: k for k, v in actions_vocab.items()}\n",
    "id_to_deprel = {v: k for k, v in deprels_vocab.items()}\n",
    "\n",
    "# 3. Cargar el Mejor Modelo Entrenado\n",
    "# Usamos el nombre del archivo que guardaste en el paso anterior\n",
    "model_path = \"High_Capacity_Model_best.keras\"  # O \"Advanced_Parser_Best.keras\" si usaste el último código\n",
    "if not os.path.exists(model_path):\n",
    "    # Fallback por si el nombre es diferente\n",
    "    model_path = \"Parser_Model.keras\" \n",
    "\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcabb2f-582a-443b-8b1b-b92f57e7ed0d",
   "metadata": {},
   "source": [
    "### Funciones Auxiliares para Inferencia\n",
    "\n",
    "Necesitamos una función que tome una lista de objetos State y los convierta en las matrices numéricas X_words y X_tags que espera el modelo.\n",
    "\n",
    "Debemos usar el mismo tamaño de ventana (nbuffer_feats y nstack_feats) que usamos durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4065d38-8c6b-48f6-a9ec-1ae5c86e9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_states(states, words_vocab, upos_vocab, nbuffer=2, nstack=2):\n",
    "    \"\"\"\n",
    "    Extrae características de un lote de estados activos y las vectoriza.\n",
    "    \"\"\"\n",
    "    batch_words = []\n",
    "    batch_tags = []\n",
    "    \n",
    "    # Usamos un Sample dummy para acceder a la lógica de extracción ya implementada\n",
    "    from algorithm import Sample\n",
    "    \n",
    "    for state in states:\n",
    "        # Creamos un sample temporal (sin transición, porque no la sabemos aún)\n",
    "        dummy_sample = Sample(state, None) \n",
    "        \n",
    "        # Extraemos features (strings)\n",
    "        feats = dummy_sample.state_to_feats(nbuffer_feats=nbuffer, nstack_feats=nstack)\n",
    "        \n",
    "        # Separar palabras y tags (la primera mitad son palabras, la segunda tags)\n",
    "        num_words = len(feats) // 2\n",
    "        words = feats[:num_words]\n",
    "        upos = feats[num_words:]\n",
    "        \n",
    "        # Vectorización: Convertir strings a IDs usando los vocabularios cargados\n",
    "        # Usamos .get(x, UNK) para manejar palabras desconocidas\n",
    "        word_ids = [words_vocab.get(w, words_vocab['<UNK>']) for w in words]\n",
    "        tag_ids = [upos_vocab.get(t, upos_vocab['<UNK>']) for t in upos]\n",
    "        \n",
    "        batch_words.append(word_ids)\n",
    "        batch_tags.append(tag_ids)\n",
    "        \n",
    "    return np.array(batch_words), np.array(batch_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc1cfe-6085-4788-b700-b4e86444dbfb",
   "metadata": {},
   "source": [
    "### Ejecución del Bucle Vertical\n",
    "\n",
    "A continuación, procesamos todas las oraciones del test set. Para no saturar la memoria, procesamos en lotes grandes (por ejemplo, 256 oraciones a la vez).\n",
    "\n",
    "Dentro del bucle, implementamos una lógica de seguridad: la red neuronal devuelve probabilidades para todas las acciones. Nosotros ordenamos esas acciones de mayor a menor probabilidad y elegimos la primera que sea válida según las reglas del Arc-Eager (función is_valid). Esto evita que el parser se rompa intentando hacer un LEFT-ARC cuando no debe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f55f503-ecfe-49d9-ac0a-afb4c9be11b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 2: Running Vertical Decoding ---\n",
      "Processing sentences 0 to 153...\n",
      "Inference completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- STEP 2: Running Vertical Decoding ---\")\n",
    "\n",
    "arc_eager = ArcEager()\n",
    "final_trees = [] # Aquí guardaremos las oraciones procesadas\n",
    "\n",
    "# Configuración\n",
    "BATCH_SIZE = 256 # Número de oraciones a procesar en paralelo\n",
    "# IMPORTANTE: Ajusta esto al valor que usaste en el entrenamiento (2, 3, o 4)\n",
    "WINDOW_SIZE = 2 \n",
    "\n",
    "idx = 0\n",
    "total_sents = len(test_sentences)\n",
    "\n",
    "while idx < total_sents:\n",
    "    # Barra de progreso simple\n",
    "    end_idx = min(idx + BATCH_SIZE, total_sents)\n",
    "    print(f\"Processing sentences {idx} to {end_idx}...\", end=\"\\r\")\n",
    "    \n",
    "    # 1. Preparar el lote inicial\n",
    "    batch_sentences = test_sentences[idx : end_idx]\n",
    "    active_states = []\n",
    "    \n",
    "    # Inicializamos los estados y limpiamos predicciones anteriores\n",
    "    for sent in batch_sentences:\n",
    "        for token in sent:\n",
    "            token.head = 0 # Reiniciamos a root por defecto\n",
    "            token.dep = \"root\" # Ojo con el formato string\n",
    "        \n",
    "        state = arc_eager.create_initial_state(sent)\n",
    "        active_states.append(state)\n",
    "    \n",
    "    # 2. Bucle hasta que todos los estados de este lote terminen\n",
    "    while active_states:\n",
    "        \n",
    "        # A. Extraer Features del lote actual\n",
    "        X_words, X_tags = get_features_from_states(\n",
    "            active_states, words_vocab, upos_vocab, \n",
    "            nbuffer=WINDOW_SIZE, nstack=WINDOW_SIZE\n",
    "        )\n",
    "        \n",
    "        # B. Predicción de la Red (Batch prediction)\n",
    "        # El modelo devuelve una lista: [probabilidades_acciones, probabilidades_etiquetas]\n",
    "        preds = model.predict([X_words, X_tags], verbose=0)\n",
    "        pred_actions_probs = preds[0] \n",
    "        pred_labels_probs = preds[1] \n",
    "        \n",
    "        # C. Aplicar transiciones y filtrar terminados\n",
    "        next_active_states = []\n",
    "        \n",
    "        for i, state in enumerate(active_states):\n",
    "            # Recuperamos probabilidades para este estado específico\n",
    "            act_probs = pred_actions_probs[i]\n",
    "            lbl_probs = pred_labels_probs[i]\n",
    "            \n",
    "            # 1. Decidir la Acción: Ordenamos de mayor a menor probabilidad\n",
    "            best_act_indices = np.argsort(act_probs)[::-1]\n",
    "            \n",
    "            # 2. Decidir la Etiqueta: Tomamos la más probable (argmax)\n",
    "            best_label_id = np.argmax(lbl_probs)\n",
    "            pred_label = id_to_deprel[best_label_id]\n",
    "            \n",
    "            # 3. Buscar la mejor acción VÁLIDA\n",
    "            transition_applied = False\n",
    "            \n",
    "            for act_id in best_act_indices:\n",
    "                act_name = id_to_action[act_id]\n",
    "                \n",
    "                # Comprobar precondiciones (Reglas del juego)\n",
    "                is_valid = False\n",
    "                if act_name == \"SHIFT\" and len(state.B) > 0:\n",
    "                     is_valid = True\n",
    "                elif act_name == \"LEFT-ARC\" and arc_eager.LA_is_valid(state):\n",
    "                    is_valid = True\n",
    "                elif act_name == \"RIGHT-ARC\" and arc_eager.RA_is_valid(state):\n",
    "                    is_valid = True\n",
    "                elif act_name == \"REDUCE\" and arc_eager.REDUCE_is_valid(state):\n",
    "                    is_valid = True\n",
    "                \n",
    "                if is_valid:\n",
    "                    # Crear transición y aplicar\n",
    "                    transition = Transition(act_name, pred_label)\n",
    "                    arc_eager.apply_transition(state, transition)\n",
    "                    transition_applied = True\n",
    "                    break \n",
    "            \n",
    "            if not transition_applied:\n",
    "                # Fallback de emergencia: Si nada es válido, forzar SHIFT o terminar\n",
    "                if len(state.B) > 0:\n",
    "                    arc_eager.apply_transition(state, Transition(\"SHIFT\"))\n",
    "                else:\n",
    "                    # Estado atascado (no debería ocurrir), lo forzamos a terminar\n",
    "                    pass\n",
    "\n",
    "            # D. Verificar si la oración ha terminado\n",
    "            if not arc_eager.final_state(state):\n",
    "                next_active_states.append(state)\n",
    "            else:\n",
    "                # --- RECONSTRUCCIÓN DEL ÁRBOL ---\n",
    "                # El estado final contiene los arcos en state.A\n",
    "                # Volcamos esa información en los tokens originales\n",
    "                arcs = state.A\n",
    "                # state.S y state.B contienen referencias a los tokens originales en 'batch_sentences'\n",
    "                # El token 0 es ROOT, los demás son 1..N\n",
    "                \n",
    "                # Mapa rápido para acceder a los tokens de esta oración por ID\n",
    "                # (Necesario porque state.A usa IDs enteros)\n",
    "                # Recopilamos todos los tokens que pasaron por el stack/buffer\n",
    "                # Como 'sent' es la lista original, usamos esa.\n",
    "                # Ojo: hay que buscar qué 'sent' corresponde a este 'state'. \n",
    "                # Pero como iteramos en orden, podemos usar un mapeo o simplemente confiar\n",
    "                # en que los tokens dentro de state.S/B son objetos únicos en memoria.\n",
    "                \n",
    "                # Manera más segura: Iterar sobre los arcos y asignar al token correspondiente\n",
    "                # Como tenemos el objeto state, podemos intentar recuperar la frase original si la guardamos,\n",
    "                # pero los tokens en state.A son solo IDs.\n",
    "                # SOLUCIÓN: Los objetos Token en state.S son los mismos que en batch_sentences.\n",
    "                # Podemos iterar sobre la oración original en batch_sentences que corresponde a este índice 'i'\n",
    "                # PERO 'i' cambia al filtrar la lista.\n",
    "                # MEJOR APROXIMACIÓN: El objeto 'state' contiene tokens. Usamos el token.id para asignar.\n",
    "                # Pero state.A tiene IDs, no objetos.\n",
    "                \n",
    "                # Truco: Al inicio del bucle grande, guardamos la tupla (state, sentence).\n",
    "                # Como aquí no lo hice, iteramos sobre batch_sentences para buscar la que coincide? No, ineficiente.\n",
    "                \n",
    "                # CORRECCIÓN EN VIVO: La lista `active_states` pierde la sincronía con `batch_sentences`.\n",
    "                # Sin embargo, los tokens son objetos mutables. Si actualizamos un token, se actualiza en la lista final.\n",
    "                # Necesitamos encontrar el objeto token que corresponde al ID 'dependent_id'.\n",
    "                \n",
    "                # Vamos a asumir que podemos acceder a los tokens desde el estado inicial o\n",
    "                # simplemente reconstruir al final.\n",
    "                # Para simplificar en este notebook, usaremos un método de \"fuerza bruta\" local:\n",
    "                # Los tokens en el stack/buffer son la referencia. Pero al final el buffer está vacío.\n",
    "                # La mejor forma es guardar la referencia a la lista de tokens dentro del estado o en una tupla.\n",
    "                pass \n",
    "\n",
    "        active_states = next_active_states\n",
    "    \n",
    "    # --- ASIGNACIÓN FINAL DE ARCOS ---\n",
    "    # Como el procesamiento vertical complica saber qué estado es qué oración al final,\n",
    "    # haremos la asignación de arcos JUSTO ANTES de eliminar el estado de active_states?\n",
    "    # No, lo más limpio es modificar el bucle anterior ligeramente.\n",
    "    \n",
    "    # *Corrección lógica para el notebook*:\n",
    "    # En lugar de 'active_states = [state]', usaremos 'active_states = [(state, sentence_tokens)]'\n",
    "    # Re-ejecuta el bucle de arriba con esta modificación mental o usa el siguiente bloque corregido:\n",
    "    \n",
    "    idx += BATCH_SIZE\n",
    "\n",
    "print(\"\\nInference completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbd69c-5366-4210-901d-09b404e5ad6f",
   "metadata": {},
   "source": [
    "### Corrección del Bucle de Inferencia (Manejo de Referencias)\n",
    "\n",
    "Para asegurarnos de asignar los padres a la oración correcta durante el procesamiento por lotes, usamos tuplas (state, sentence) en la lista activa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a672cda-8e33-4a93-96b6-cdb9ff58c481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentences 0 to 153...\n",
      "Decoding finished.\n"
     ]
    }
   ],
   "source": [
    "# --- BUCLE DE INFERENCIA CORREGIDO Y COMPLETO ---\n",
    "final_trees = []\n",
    "idx = 0\n",
    "\n",
    "while idx < total_sents:\n",
    "    end_idx = min(idx + BATCH_SIZE, total_sents)\n",
    "    print(f\"Processing sentences {idx} to {end_idx}...\", end=\"\\r\")\n",
    "    \n",
    "    batch_sentences = test_sentences[idx : end_idx]\n",
    "    \n",
    "    # Guardamos pares (Estado, ListaDeTokensOriginal)\n",
    "    active_pairs = [] \n",
    "    \n",
    "    for sent in batch_sentences:\n",
    "        # Limpieza inicial\n",
    "        for token in sent:\n",
    "            token.head = \"_\" \n",
    "            token.dep = \"_\"\n",
    "        state = arc_eager.create_initial_state(sent)\n",
    "        active_pairs.append((state, sent))\n",
    "    \n",
    "    while active_pairs:\n",
    "        # Desempaquetar solo estados para feature extraction\n",
    "        current_states = [p[0] for p in active_pairs]\n",
    "        \n",
    "        X_words, X_tags = get_features_from_states(\n",
    "            current_states, words_vocab, upos_vocab, \n",
    "            nbuffer=WINDOW_SIZE, nstack=WINDOW_SIZE\n",
    "        )\n",
    "        \n",
    "        preds = model.predict([X_words, X_tags], verbose=0)\n",
    "        pred_actions = preds[0]\n",
    "        pred_labels = preds[1]\n",
    "        \n",
    "        next_active_pairs = []\n",
    "        \n",
    "        for i, (state, sent_tokens) in enumerate(active_pairs):\n",
    "            # ... (Lógica de selección de mejor acción igual que antes) ...\n",
    "            act_probs = pred_actions[i]\n",
    "            lbl_probs = pred_labels[i]\n",
    "            best_act_indices = np.argsort(act_probs)[::-1]\n",
    "            best_label_id = np.argmax(lbl_probs)\n",
    "            pred_label = id_to_deprel[best_label_id]\n",
    "            \n",
    "            transition_applied = False\n",
    "            for act_id in best_act_indices:\n",
    "                act_name = id_to_action[act_id]\n",
    "                is_valid = False\n",
    "                # Chequeos de validez\n",
    "                if act_name == \"SHIFT\" and len(state.B) > 0: is_valid = True\n",
    "                elif act_name == \"LEFT-ARC\" and arc_eager.LA_is_valid(state): is_valid = True\n",
    "                elif act_name == \"RIGHT-ARC\" and arc_eager.RA_is_valid(state): is_valid = True\n",
    "                elif act_name == \"REDUCE\" and arc_eager.REDUCE_is_valid(state): is_valid = True\n",
    "                \n",
    "                if is_valid:\n",
    "                    arc_eager.apply_transition(state, Transition(act_name, pred_label))\n",
    "                    transition_applied = True\n",
    "                    break\n",
    "            \n",
    "            if not transition_applied and len(state.B) > 0:\n",
    "                arc_eager.apply_transition(state, Transition(\"SHIFT\"))\n",
    "\n",
    "            # Chequeo de estado final\n",
    "            if not arc_eager.final_state(state):\n",
    "                next_active_pairs.append((state, sent_tokens))\n",
    "            else:\n",
    "                # --- VOLCADO DE RESULTADOS ---\n",
    "                # Ahora sí tenemos acceso a 'sent_tokens' garantizado\n",
    "                generated_arcs = state.A # set de (head, label, dep)\n",
    "                \n",
    "                for (head_id, label, dep_id) in generated_arcs:\n",
    "                    # dep_id corresponde al índice en la lista sent_tokens?\n",
    "                    # Generalmente Token.id empieza en 1. sent_tokens[0] es ROOT(id=0).\n",
    "                    # Entonces sent_tokens[dep_id] es el token correcto.\n",
    "                    if dep_id < len(sent_tokens):\n",
    "                        sent_tokens[dep_id].head = head_id\n",
    "                        sent_tokens[dep_id].dep = label\n",
    "                        \n",
    "        active_pairs = next_active_pairs\n",
    "        \n",
    "    final_trees.extend(batch_sentences)\n",
    "    idx += BATCH_SIZE\n",
    "\n",
    "print(\"\\nDecoding finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ebb71-c95a-478f-bfe2-5139a9c864dd",
   "metadata": {},
   "source": [
    "## 6. Post-processing and Saving\n",
    "\n",
    "Los árboles generados por un parser \"greedy\" (codicioso) como este pueden tener pequeños defectos estructurales, como tener múltiples raíces o nodos sin padre. Usamos el PostProcessor para aplicar reglas heurísticas y arreglar estos árboles antes de guardar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ad1df90-3188-46fb-88c2-2c72551212d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 3: Post-processing and Saving ---\n",
      "Final predictions saved to: system_prediction.conllu\n"
     ]
    }
   ],
   "source": [
    "print(\"--- STEP 3: Post-processing and Saving ---\")\n",
    "\n",
    "output_filename = \"system_prediction.conllu\"\n",
    "\n",
    "# 1. Guardar la predicción cruda\n",
    "reader.write_conllu_file(output_filename, final_trees)\n",
    "\n",
    "# 2. Aplicar correcciones (Single Root, Connected Tree)\n",
    "postprocessor = PostProcessor()\n",
    "corrected_trees = postprocessor.postprocess(output_filename)\n",
    "\n",
    "# 3. Sobreescribir con la versión corregida\n",
    "reader.write_conllu_file(output_filename, corrected_trees)\n",
    "\n",
    "print(f\"Final predictions saved to: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854c9a4-f593-47c8-aee6-e81ec8bd58f6",
   "metadata": {},
   "source": [
    "## 7. Official Evaluation\n",
    "\n",
    "Finalmente, usamos el script conll18_ud_eval.py para comparar nuestra predicción (system_prediction.conllu) contra el archivo de referencia (en_partut-ud-test_clean.conllu).\n",
    "\n",
    "Las métricas principales son:\n",
    "\n",
    "    UAS (Unlabeled Attachment Score): % de padres correctos.\n",
    "\n",
    "    LAS (Labeled Attachment Score): % de padres Y etiquetas correctos (La métrica más importante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ece526f4-f2d4-4c06-94b8-b042a6c10112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 4: Official Evaluation ---\n",
      "Running command: python conll18_ud_eval.py en_partut-ud-test_clean.conllu system_prediction.conllu -v\n",
      "\n",
      "Metric     | Precision |    Recall |  F1 Score | AligndAcc\n",
      "-----------+-----------+-----------+-----------+-----------\n",
      "Tokens     |    100.00 |    100.00 |    100.00 |\n",
      "Sentences  |    100.00 |    100.00 |    100.00 |\n",
      "Words      |    100.00 |    100.00 |    100.00 |\n",
      "UPOS       |    100.00 |    100.00 |    100.00 |    100.00\n",
      "XPOS       |    100.00 |    100.00 |    100.00 |    100.00\n",
      "UFeats     |    100.00 |    100.00 |    100.00 |    100.00\n",
      "AllTags    |    100.00 |    100.00 |    100.00 |    100.00\n",
      "Lemmas     |    100.00 |    100.00 |    100.00 |    100.00\n",
      "UAS        |     78.52 |     78.52 |     78.52 |     78.52\n",
      "LAS        |     69.01 |     69.01 |     69.01 |     69.01\n",
      "CLAS       |     57.82 |     54.58 |     56.15 |     54.58\n",
      "MLAS       |     56.51 |     53.34 |     54.88 |     53.34\n",
      "BLEX       |     57.82 |     54.58 |     56.15 |     54.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--- STEP 4: Official Evaluation ---\")\n",
    "\n",
    "# Definir archivos\n",
    "gold_file = \"en_partut-ud-test_clean.conllu\"\n",
    "system_file = \"system_prediction.conllu\"\n",
    "\n",
    "# Ejecutar el script de evaluación\n",
    "# Usamos os.system para simular la ejecución en terminal\n",
    "import os\n",
    "command = f\"python conll18_ud_eval.py {gold_file} {system_file} -v\"\n",
    "\n",
    "print(f\"Running command: {command}\\n\")\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b9a073-352d-400b-b31f-e9792f4ca4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
